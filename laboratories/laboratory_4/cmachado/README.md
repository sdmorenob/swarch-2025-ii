# An√°lisis t√©cnico de patrones arquitect√≥nicos

## A) In your own technical words, what is the fundamental problem that the Microfrontends pattern aims to solve? How does it solve it?

### A.1) Microfrontends

### Problema principal que pretende resolver
Los **microfrontends** abordan el problema del **monolitismo en la capa de presentaci√≥n**: un frontend grande y acoplado que dificulta el desarrollo paralelo, los despliegues independientes, la evoluci√≥n tecnol√≥gica y la escalabilidad del proceso de entrega.  
Tambi√©n solucionan la falta de **l√≠mites de responsabilidad claros** dentro de aplicaciones web complejas, reduciendo tiempos de compilaci√≥n, pruebas y riesgos de regresi√≥n.

### C√≥mo lo hace (t√©cnicamente)
- **Fragmentaci√≥n por dominio o funcionalidad:** la interfaz se divide en m√≥dulos independientes (por ruta, √°rea funcional o widget), cada uno mantenido por un equipo.  
- **Composici√≥n flexible:** los m√≥dulos se ensamblan en tiempo de *build* o en tiempo de ejecuci√≥n mediante:
  - *Server-side composition* (ensamblado en el servidor),
  - *Client-side composition* (carga din√°mica),
  - *Iframes* (aislamiento fuerte),
  - *Webpack Module Federation* (compartici√≥n controlada de c√≥digo).  
- **Despliegue independiente:** cada microfrontend se construye y publica como artefacto aut√≥nomo, permitiendo versiones desacopladas.  
- **Aislamiento t√©cnico:** se evitan conflictos de CSS/JS usando *CSS Modules*, *Shadow DOM* o *namespaces*.  
- **Contratos bien definidos:** la comunicaci√≥n entre m√≥dulos se basa en APIs, eventos o props, usando REST/GraphQL o *custom events*.  
- **Gesti√≥n de dependencias compartidas:** librer√≠as comunes (p. ej. React, Vue) pueden compartirse en tiempo de ejecuci√≥n o empacarse individualmente.  

**Consecuencia t√©cnica:** mayor autonom√≠a de equipos y velocidad de entrega, pero con mayor complejidad en orquestaci√≥n, rendimiento y gobernanza.


### A.2) Log Aggregation

### Problema principal que pretende resolver
El patr√≥n de **agregaci√≥n de logs** aborda la falta de **observabilidad centralizada** en sistemas distribuidos.  
En entornos de microservicios, los registros est√°n dispersos entre m√∫ltiples instancias y contenedores, lo que dificulta su b√∫squeda, correlaci√≥n y an√°lisis.  
Sin una estrategia de agregaci√≥n, depurar fallos, auditar y generar alertas es ineficiente.

### C√≥mo lo hace (t√©cnicamente)
- **Recolecci√≥n distribuida:** agentes ligeros (p. ej. *Filebeat*, *Fluentd*, *Vector*, *Promtail*) capturan logs desde archivos locales, `stdout`, `stderr` o sistemas de logging del host.  
- **Normalizaci√≥n y estructuraci√≥n:** los registros se transforman en formato estructurado (JSON) y se enriquecen con metadatos como `timestamp`, `host`, `service`, `trace-id` o `severity`.  
- **Transporte confiable:** los agentes env√≠an los datos a un *pipeline* central mediante protocolos como HTTP, gRPC, Kafka o Syslog, con *buffering* y reintentos.  
- **Indexaci√≥n y almacenamiento centralizado:** herramientas como *ELK/EFK Stack*, *Graylog*, *Splunk* o *Loki* almacenan e indexan los eventos para consultas r√°pidas.  
- **Correlaci√≥n de eventos:** se usan identificadores globales (`trace-id`, `request-id`) para reconstruir el flujo de ejecuci√≥n entre servicios.  
- **Procesamiento y retenci√≥n:** los *pipelines* aplican filtros, alertas y pol√≠ticas de retenci√≥n (niveles *hot/warm/cold*).  
- **Consulta y monitoreo:** paneles, b√∫squedas ad-hoc y alertas automatizadas permiten detecci√≥n y diagn√≥stico r√°pido de problemas.  
- **Seguridad y acceso:** control mediante roles, cifrado en tr√°nsito y pol√≠ticas sobre √≠ndices o buckets.

**Consecuencia t√©cnica:** mejora la visibilidad y reduce el tiempo de resoluci√≥n de incidentes, aunque introduce costes y complejidad en la infraestructura de observabilidad.

---

## B) How does this pattern impact system coupling and cohesion?


### B.1) Microfrontends

### Acoplamiento
El patr√≥n de **microfrontends** busca **reducir el acoplamiento** entre las partes del sistema en la capa de presentaci√≥n.  
Cada m√≥dulo (microfrontend) es aut√≥nomo y se comunica con otros mediante **interfaces bien definidas** (APIs o eventos), evitando dependencias directas de c√≥digo.  
Sin embargo, puede aparecer **acoplamiento impl√≠cito** si los m√≥dulos comparten estados globales, estilos o librer√≠as de manera descontrolada.

- **Efecto t√©cnico:** acoplamiento *d√©bil* a nivel de despliegue y c√≥digo, pero riesgo de acoplamiento *l√≥gico* si no se definen l√≠mites claros de dominio.

### Cohesi√≥n
Los microfrontends **aumentan la cohesi√≥n** interna al organizar cada m√≥dulo alrededor de un dominio funcional o contexto de negocio (p. ej. ‚ÄúCat√°logo‚Äù, ‚ÄúCarrito‚Äù, ‚ÄúPerfil‚Äù).  
Esto refuerza la responsabilidad √∫nica del m√≥dulo y facilita su evoluci√≥n independiente.

- **Efecto t√©cnico:** cohesi√≥n *alta* dentro de cada microfrontend, al estar orientado a un objetivo funcional espec√≠fico.



### B.2) Log Aggregation

### Acoplamiento
La **agregaci√≥n de logs** introduce un **acoplamiento indirecto** entre los servicios y la infraestructura de observabilidad.  
Cada componente debe emitir logs en un formato o protocolo compatible con el sistema central (p. ej. JSON estructurado, uso de `trace-id`).  
Sin embargo, este acoplamiento es **d√©bil y t√©cnico**, no funcional: los servicios no dependen entre s√≠, solo del mecanismo de logging.

- **Efecto t√©cnico:** acoplamiento *t√©cnico d√©bil* hacia un sistema de observabilidad com√∫n, manteniendo independencia entre microservicios.

### Cohesi√≥n
Este patr√≥n **aumenta la cohesi√≥n transversal** del sistema, ya que centraliza la responsabilidad de monitoreo y an√°lisis en un √∫nico punto.  
No afecta directamente la cohesi√≥n funcional de los servicios, pero mejora la coherencia en c√≥mo el sistema maneja la trazabilidad y el diagn√≥stico.

- **Efecto t√©cnico:** cohesi√≥n *alta* en el subsistema de observabilidad, sin impacto negativo en la cohesi√≥n interna de los servicios.

---

### Conclusi√≥n t√©cnica

| Patr√≥n           | Acoplamiento                               | Cohesi√≥n                                          |
|------------------|---------------------------------------------|--------------------------------------------------|
| **Microfrontends** | D√©bil entre m√≥dulos, fuerte si comparten estado o dependencias globales | Alta dentro de cada m√≥dulo funcional |
| **Log Aggregation** | D√©bil y t√©cnico hacia la infraestructura de logging | Alta en el dominio de observabilidad |

Ambos patrones, bien aplicados, tienden a **reducir el acoplamiento** y **aumentar la cohesi√≥n** dentro de sus respectivos √°mbitos, contribuyendo a sistemas m√°s mantenibles y escalables.

## C) Explain the fundamental mechanism of the pattern.

### C.1) Microfrontends

### Mecanismo fundamental
El patr√≥n **Microfrontends** se basa en **dividir la interfaz de usuario monol√≠tica** en m√∫ltiples **m√≥dulos front-end independientes**, donde cada uno representa una parte funcional del sistema y es desarrollado, desplegado y versionado de manera aut√≥noma.

Cada microfrontend:
- Se **integra din√°micamente** en la aplicaci√≥n principal (a menudo llamada *shell* o *host*) mediante t√©cnicas como:
  - **Module Federation** (Webpack 5),
  - **iframes**,
  - **Web Components**, o
  - **Single-SPA / import remoto**.
- Se comunica con otros m√≥dulos a trav√©s de **eventos**, **mensajes** o **APIs compartidas**, evitando referencias directas de c√≥digo.
- Mantiene su propio **ciclo de vida independiente**: puede actualizarse o escalarse sin afectar a los dem√°s.

En resumen, el mecanismo clave es la **composici√≥n din√°mica de interfaces distribuidas**, donde cada m√≥dulo es una unidad funcional aut√≥noma que coopera en tiempo de ejecuci√≥n para formar la aplicaci√≥n completa.


### C.2) Log Aggregation

### Mecanismo fundamental
El patr√≥n **Log Aggregation** funciona mediante la **recolecci√≥n, normalizaci√≥n y centralizaci√≥n de registros (logs)** generados por los distintos microservicios de un sistema distribuido.

El proceso t√≠pico implica tres pasos t√©cnicos:

1. **Emisi√≥n de logs estructurados:**  
   Cada servicio genera registros en un formato uniforme (generalmente JSON), incluyendo metadatos como `timestamp`, `service-id`, `trace-id` y `log-level`.

2. **Transporte y almacenamiento centralizado:**  
   Los logs se env√≠an ‚Äîmediante protocolos como **Fluentd**, **Logstash**, o **Filebeat**‚Äî a un **sistema de agregaci√≥n** (por ejemplo, **Elasticsearch**, **Graylog**, **Splunk**, o **Grafana Loki**).

3. **Indexaci√≥n y an√°lisis:**  
   Los datos son indexados para permitir **b√∫squeda, correlaci√≥n y visualizaci√≥n** de eventos, facilitando el monitoreo, la trazabilidad de errores y la auditor√≠a del sistema.

En esencia, el mecanismo clave es la **canalizaci√≥n centralizada de eventos de logging**, que convierte flujos de logs distribuidos en informaci√≥n estructurada y consultable.

---

### Comparaci√≥n t√©cnica

| Patr√≥n | Mecanismo central | Nivel de operaci√≥n |
|--------|--------------------|--------------------|
| **Microfrontends** | Composici√≥n din√°mica de interfaces front-end independientes | Capa de presentaci√≥n |
| **Log Aggregation** | Centralizaci√≥n y an√°lisis de logs estructurados emitidos por m√∫ltiples servicios | Capa de observabilidad / infraestructura |

Ambos patrones aportan independencia modular, pero en niveles distintos del sistema: uno en la **UI** y otro en la **monitorizaci√≥n**.

## D) Illustrate the architecture at a high level.

### D.1) Microfrontends
![alt text](Microfontends.png)

### D.2) Log aggregation
![alt text](Log_aggregation.png)

## E) What are the main benefits?

| Patr√≥n             | Enfoque               | Beneficios clave                                                   |
|--------------------|------------------------|---------------------------------------------------------------------|
| **Microfrontends** | Frontend (UI)          | Escalabilidad, autonom√≠a de equipos, despliegue independiente       |
| **Log Aggregation**| Observabilidad / Logs  | Visibilidad global, trazabilidad, monitoreo, auditor√≠a              |


## F) What complexities or downsides appear? What trade-offs does it introduce in terms of performance, complexity, or security?

### Microfrontends

- **Coordinaci√≥n entre equipos**
  - Aunque los equipos son independientes, a√∫n deben alinearse en ciertos est√°ndares (UI, dise√±o, rutas, etc.).

- **Carga inicial y rendimiento**
  - Cargar m√∫ltiples bundles JavaScript puede afectar el tiempo de carga si no se optimiza correctamente.

- **Gesti√≥n del estado global**
  - Compartir o sincronizar el estado entre microfrontends (por ejemplo, sesi√≥n de usuario) puede ser complejo.

- **Routing y navegaci√≥n**
  - Implementar un sistema de rutas com√∫n sin colisiones entre microfrontends requiere una estrategia clara (por ejemplo, routing basado en host o en rutas hijas).

- **Consistencia visual**
  - Mantener una experiencia de usuario coherente (estilos, componentes, comportamiento) entre microfrontends es dif√≠cil si no hay un dise√±o centralizado.

- **Sobrecarga tecnol√≥gica**
  - Si se usan m√∫ltiples frameworks (React, Angular, etc.), puede haber duplicaci√≥n de librer√≠as, aumentando el tama√±o del bundle.

---

### Log Aggregation

- **Volumen de datos**
  - En sistemas con muchos microservicios, el volumen de logs puede crecer exponencialmente, afectando rendimiento y costos de almacenamiento.

- **Formato de logs inconsistente**
  - Si los equipos no siguen un est√°ndar de log (JSON, campos clave, nivel de severidad), se dificulta el an√°lisis y la b√∫squeda.

- **Correlaci√≥n entre servicios**
  - Requiere implementar correctamente **IDs de correlaci√≥n** (trace IDs) para seguir el rastro de una solicitud entre servicios.

- **Complejidad operativa**
  - Configurar, mantener y escalar herramientas como ELK, Loki, o Fluentd requiere conocimiento especializado.

- **Latencia en el acceso**
  - En algunos casos, los logs no aparecen en tiempo real debido a buffers, reintentos o problemas de red.

- **Seguridad y privacidad**
  - Los logs pueden contener datos sensibles; es fundamental aplicar pol√≠ticas de anonimizaci√≥n y control de acceso.

## G) Describe a realistic system that would use this pattern.

### Microfrontends ‚Äì Plataforma de eCommerce

Una tienda online grande (como Amazon o Mercado Libre) divide su sitio web en m√≥dulos independientes: productos, carrito, pagos, perfil, etc.
Cada m√≥dulo es desarrollado y desplegado por un equipo distinto, usando tecnolog√≠as diferentes (React, Vue, Angular).
Esto permite mayor autonom√≠a, actualizaciones r√°pidas y escalabilidad en el frontend.

### Log Aggregation ‚Äì Plataforma SaaS de gesti√≥n empresarial

Una app SaaS con m√∫ltiples microservicios (autenticaci√≥n, pagos, notificaciones, reportes) centraliza todos sus logs usando herramientas como Elasticsearch + Kibana o Grafana Loki.
Cada servicio env√≠a logs estructurados con un ID de trazabilidad. Esto facilita el monitoreo, la depuraci√≥n y la auditor√≠a de errores en entornos distribuidos.

 ---
# Analisis de los escenario especificos


## Escenario 1 ‚Äì PagoGlobal

### Contexto resumido

- **Empresa:** PagoGlobal, fintech colombiana.
- **Servicio cr√≠tico:** `PaymentProcessor`, maneja millones de transacciones.
- **Dependencia externa:** `FraudBlocker`, usado solo para transacciones > $100,000 COP.
- **Problema:** `FraudBlocker` no falla, pero se vuelve extremadamente lento en picos (brownout), causando:

  - Bloqueo del thread pool de `PaymentProcessor`.
  - Rechazo de todas las solicitudes, incluso las que no requieren validaci√≥n de fraude.
  - Ca√≠da total durante 45 minutos con gran impacto econ√≥mico.

---

### An√°lisis profundo del escenario

### Naturaleza del problema

- **Brownouts son m√°s peligrosos que fallos totales:** el servicio lento no activa mecanismos de error tradicionales.
- **Bloqueo por dise√±o sin control de recursos:** las llamadas a `FraudBlocker` bloquean el mismo recurso que otras operaciones cr√≠ticas.
- **Falta de aislamiento:** una dependencia no esencial para todas las operaciones causa una ca√≠da total.
- **Timeout inadecuado:** 20 segundos por llamada es demasiado para un servicio de alta concurrencia.
- **Riesgo de cascada:** cuando los recursos (hilos) se agotan, el sistema completo falla.

---

## Caracter√≠sticas clave del sistema

| Caracter√≠stica                          | Implicaci√≥n arquitect√≥nica                            |
|----------------------------------------|--------------------------------------------------------|
| Alta concurrencia                      | Se requieren soluciones no bloqueantes o aisladas     |
| Dependencia cr√≠tica con rendimiento variable | Se necesita protecci√≥n frente a degradaci√≥n         |
| L√≥gica condicional (fraude > $100,000) | Posible separaci√≥n del flujo cr√≠tico y no cr√≠tico     |
| Impacto total por fallo parcial        | Se necesita contener el impacto de fallos externos    |

---

## Recomendaci√≥n arquitect√≥nica: 2 patrones clave

### 1. Circuit Breaker

#### Qu√© es:
Un mecanismo que "abre el circuito" y deja de llamar a un servicio cuando detecta que est√° fallando o est√° lento.

#### Por qu√© es adecuado aqu√≠:

- Evita hacer m√°s llamadas a `FraudBlocker` cuando ya est√° lento.
- Libera recursos en `PaymentProcessor` y evita saturaci√≥n por espera.
- Permite definir un fallback (por ejemplo, rechazar o marcar transacci√≥n como "pendiente").

#### C√≥mo implementarlo:
- Usar herramientas como **Resilience4j**, **Istio**, o **Envoy**.
- Configurar:
  - **Timeout:** 2‚Äì3 segundos.
  - **Thresholds:** n√∫mero de fallos o lentitud para abrir el circuito.
  - **Recovery time:** para volver a probar despu√©s de cierto tiempo.

---

### 2. Bulkhead

#### Qu√© es:
Un patr√≥n que separa recursos (como hilos, procesos o contenedores) para que una parte del sistema no afecte a otra.

#### Por qu√© es adecuado aqu√≠:

- Permite aislar las llamadas a `FraudBlocker` en su propio grupo de recursos (por ejemplo, un thread pool separado).
- Si el pool se llena, solo las transacciones > $100,000 COP fallan.
- Las transacciones normales (< $100,000) siguen siendo procesadas con normalidad.

#### C√≥mo implementarlo:
- Configurar un **pool de hilos dedicado** para las llamadas a `FraudBlocker`.
- O separar en un **microservicio especializado de validaci√≥n antifraude**, que el `PaymentProcessor` invoque solo cuando sea necesario.

---

## Alternativa a considerar a mediano plazo

### Queue-Based Isolation (asincron√≠a con colas)

Convertir el chequeo de fraude en una tarea asincr√≥nica para desacoplar completamente del flujo en tiempo real. Sin embargo, **esto implica cambios en la experiencia del usuario y en los flujos de negocio**, por lo que es mejor considerarlo como un redise√±o a mediano plazo.

---

## Conclusi√≥n final

> **El problema no es que `FraudBlocker` falle, sino que lo hace lentamente y sin control, afectando todo el sistema.**

Por tanto, la soluci√≥n debe enfocarse en **aislar el impacto de la dependencia lenta** y **proteger el n√∫cleo del sistema de pagos**.

### Patrones recomendados:

1. **Circuit Breaker** ‚Äì Para detectar y cortar llamadas lentas a `FraudBlocker`.
2. **Bulkhead** ‚Äì Para aislar recursos y evitar que una parte del sistema bloquee a todo lo dem√°s.

Aplicados correctamente, estos patrones garantizar√°n que:

- Las transacciones que **no requieren fraude** sigan funcionando.
- Las llamadas a `FraudBlocker` **no saturen** el sistema.
- El sistema degrade con gracia, **sin colapsar completamente**.

 ## Escenario 2 - MiSalud Digital

## üìò Contexto resumido

- **Plataforma:** MiSalud Digital, sistema de historia cl√≠nica electr√≥nica nacional.
- **Estructura:** M√°s de 70 microservicios, desarrollados por m√∫ltiples equipos en diferentes lenguajes.
- **Problemas cr√≠ticos detectados antes del lanzamiento:**

1. Requisito de **seguridad Zero-Trust** con **mutual TLS (mTLS)** obligatorio entre servicios.
2. Necesidad de **auditor√≠a fina y centralizada** para accesos a datos sensibles.
3. Soporte para **canary releases** (ej. 1% de tr√°fico a nueva versi√≥n).
4. Inconsistencia total en **resiliencia** (timeouts, retries) por diferencias entre tecnolog√≠as y librer√≠as personalizadas.
5. Uso de "common libraries" ha resultado ineficiente y dif√≠cil de mantener.



## An√°lisis profundo del escenario

| Caracter√≠stica                         | Implicaci√≥n arquitect√≥nica                               |
|----------------------------------------|-----------------------------------------------------------|
| Arquitectura grande (70+ servicios)   | Alta complejidad operativa                                |
| Equipos independientes y poliglotas   | Dif√≠cil estandarizar l√≥gica dentro del c√≥digo             |
| Requisitos de seguridad cr√≠ticos      | Necesario aplicar pol√≠ticas a nivel de red, no solo c√≥digo|
| Auditor√≠a y trazabilidad              | Centralizaci√≥n y protecci√≥n contra manipulaci√≥n           |
| Despliegue progresivo                 | Requiere control avanzado de tr√°fico                      |
| Inconsistencia en resiliencia         | Riesgo de comportamiento no predecible en fallos          |

---

## Recomendaci√≥n arquitect√≥nica: 1 patr√≥n principal

### **Service Mesh** (üîë Patr√≥n m√°s adecuado)

#### Qu√© es:
Una capa de infraestructura que se encarga de la comunicaci√≥n entre microservicios, **desacoplando la l√≥gica de red, seguridad, auditor√≠a y resiliencia del c√≥digo de aplicaci√≥n**.

Herramientas comunes: **Istio**, **Linkerd**, **Consul Connect**

---

## Por qu√© Service Mesh es ideal aqu√≠

### 1. Seguridad Zero-Trust con mTLS

- Service Mesh gestiona autom√°ticamente certificados TLS y autenticaci√≥n mutua entre servicios.
- No requiere que cada servicio implemente su propio stack de seguridad.
- Cumple f√°cilmente con los requisitos de cifrado interno exigidos por regulaci√≥n.

### 2. Auditor√≠a de tr√°fico a nivel de red

- Permite **observabilidad detallada** de cada llamada entre servicios: origen, destino, URL, latencia.
- Logs generados por el **sidecar proxy** (como Envoy) son **externos e inmutables**, cumpliendo con requisitos de no manipulaci√≥n.

### 3. Canary Releases / Progressive Rollouts

- Service Mesh puede enrutar din√°micamente porcentajes espec√≠ficos de tr√°fico a diferentes versiones.
- Ejemplo: 1% al nuevo `Appointment-Scheduler v2`, 99% al estable.
- Todo configurable sin tocar el c√≥digo de los servicios.

### 4. Resiliencia consistente

- Timeouts, retries, circuit breakers y pol√≠ticas de fallos se configuran de forma **uniforme** a nivel de malla.
- Se eliminan las diferencias entre implementaciones en Java, Node.js, Python, etc.
- Los desarrolladores no tienen que implementar esa l√≥gica en cada lenguaje.

---

## Alternativa descartada: Common Libraries

Aunque parec√≠a una soluci√≥n l√≥gica, ha demostrado ser:

- Lenta de mantener.
- Dif√≠cil de coordinar entre 70+ servicios.
- Inviable en entornos poliglotas.
- Incompatible con cambios r√°pidos en pol√≠ticas de seguridad o monitoreo.

---

## Conclusi√≥n final

> **El problema principal no es t√©cnico, sino de gobernanza, estandarizaci√≥n y control operacional a escala.**

Por tanto, la soluci√≥n debe abstraer la l√≥gica com√∫n fuera del c√≥digo, y gestionarla de forma centralizada y consistente.

### Patr√≥n recomendado:

| Patr√≥n         | Por qu√© aplicarlo                                          |
|----------------|------------------------------------------------------------|
| **Service Mesh** | Proporciona seguridad, auditor√≠a, resiliencia y routing progresivo sin tocar el c√≥digo |

---

## Beneficios directos de aplicar Service Mesh

| Requisito del escenario       | Resuelto con Service Mesh        |
|-------------------------------|----------------------------------|
| mTLS obligatorio              |  Certificados autom√°ticos y rotaci√≥n |
| Auditor√≠a completa            |  Logging de tr√°fico externo y estructurado |
| Canary releases               |  Routing granular por porcentaje, headers, etc. |
| Resiliencia inconsistente     |  Timeouts, retries y circuit breakers centralizados |
| Poliglotismo + 70 servicios   | ‚úÖDesacopla l√≥gica com√∫n del lenguaje y del equipo |

