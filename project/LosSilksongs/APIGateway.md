# API Gateway - MusicShare

Este documento describe la configuraci√≥n y funcionamiento del API Gateway en el proyecto MusicShare, que utiliza **Traefik** como proxy inverso y punto de entrada √∫nico para todos los servicios.

## üìñ Concepto Clave: API Gateway con Traefik

Nuestra arquitectura utiliza **Traefik** como API Gateway, un proxy inverso moderno que:
- **Enruta autom√°ticamente** las peticiones a los servicios correctos
- **Descubre servicios** autom√°ticamente mediante Docker labels
- **Maneja SSL/TLS** para conexiones seguras
- **Balancea carga** entre instancias de servicios
- **Proporciona un dashboard** para monitoreo en tiempo real

**A Traefik no le importa la l√≥gica interna de los servicios, solo le importa la ruta y el puerto al que debe dirigir las solicitudes.**

## üèóÔ∏è Arquitectura del API Gateway

```
Internet/Cliente
       ‚Üì
   Traefik (Puerto 80/443)
       ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ  Enrutamiento por PathPrefix   ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ                                                     ‚îÇ
   ‚îú‚îÄ‚Üí /api/users      ‚Üí UserService (8002)            ‚îÇ
   ‚îú‚îÄ‚Üí /api/music      ‚Üí MusicService (8081)           ‚îÇ
   ‚îú‚îÄ‚Üí /api/social     ‚Üí SocialService (8083)          ‚îÇ
   ‚îú‚îÄ‚Üí /api/notifications ‚Üí NotificationService (8082) ‚îÇ
   ‚îú‚îÄ‚Üí /ws             ‚Üí NotificationService WebSocket ‚îÇ
   ‚îú‚îÄ‚Üí /upload         ‚Üí Next.js SSR (3000)            ‚îÇ
   ‚îú‚îÄ‚Üí /formulario-post ‚Üí Formulario Post Frontend (80)‚îÇ
   ‚îî‚îÄ‚Üí /               ‚Üí Frontend React (80)           ‚îÇ
       (prioridad 1, catch-all)                        ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## ‚úÖ Servicios Configurados en el API Gateway

### 1. **UserService** (Puerto 8002)
- **Ruta**: `/api/users`
- **Middleware**: Strip prefix `/api/users`
- **Ejemplos de endpoints**:
  - `https://musicshare.com/api/users/auth/token` ‚Üí `http://userservice:8002/auth/token`
  - `https://musicshare.com/api/users/me` ‚Üí `http://userservice:8002/me`

### 2. **MusicService** (Puerto 8081)
- **Ruta**: `/api/music`
- **Middleware**: Strip prefix `/api/music`
- **Ejemplos de endpoints**:
  - `https://musicshare.com/api/music/tracks` ‚Üí `http://music-service:8081/tracks`
  - `https://musicshare.com/api/music/playlists` ‚Üí `http://music-service:8081/playlists`

### 3. **SocialService** (Puerto 8083)
- **Ruta**: `/api/social`
- **Middleware**: Strip prefix `/api/social`
- **Rutas adicionales**: `/swagger-ui`, `/v3/api-docs` (sin strip prefix para Swagger)
- **Ejemplos de endpoints**:
  - `https://musicshare.com/api/social/posts` ‚Üí `http://social-service:8083/posts`
  - `https://musicshare.com/swagger-ui` ‚Üí `http://social-service:8083/swagger-ui`

### 4. **NotificationService** (Puerto 8082)
- **Ruta REST**: `/api/notifications`
- **Ruta WebSocket**: `/ws`
- **Middleware**: Strip prefix `/api/notifications` (solo para REST)
- **Ejemplos**:
  - `https://musicshare.com/api/notifications/send` ‚Üí `http://notificationservice:8082/send`
  - `wss://musicshare.com/ws` ‚Üí `ws://notificationservice:8082/ws`

### 5. **Frontend React** (Puerto 80)
- **Ruta**: `/` (catch-all)
- **Prioridad**: 1 (m√°s baja, se eval√∫a al final)
- **Sin strip prefix**: Sirve la aplicaci√≥n React tal cual

### 6. **Next.js SSR - Upload** (Puerto 3000)
- **Ruta**: `/upload`
- **Prioridad**: 2 (m√°s alta que el frontend general)
- **Sin strip prefix**: Next.js maneja internamente la ruta `/upload`

### 7. **Formulario Post Frontend** (Puerto 80)
- **Ruta**: `/formulario-post`
- **Middleware**: Strip prefix `/formulario-post`
- **Microfrontend** para creaci√≥n de posts

## ‚ö†Ô∏è Servicios NO Configurados en el API Gateway

### **SearchService** ‚ùå
- **Estado**: Carpeta vac√≠a (solo `.gitkeep`)
- **Acci√≥n requerida**: Implementar el servicio antes de configurar en Traefik
- **Ruta sugerida**: `/api/search`

### **MetadataService** ‚ùå
- **Estado**: Implementado pero NO expuesto a trav√©s del API Gateway
- **Raz√≥n**: Es un servicio gRPC interno (puerto 50051)
- **Uso**: Solo es consumido por MusicService internamente
- **No requiere exposici√≥n p√∫blica**: Correcto seg√∫n arquitectura de microservicios

## ÔøΩ Configuraci√≥n de Traefik

### Archivo `traefik/traefik.yml`
```yaml
api:
  dashboard: true
  insecure: true # Solo desarrollo

entryPoints:
  web:
    address: ":80"
    http:
      redirections:
        entryPoint:
          to: websecure
          scheme: https
  websecure:
    address: ":443"

providers:
  docker:
    endpoint: "unix:///var/run/docker.sock"
    exposedByDefault: false
    watch: true
    network: backend_net

accessLog: {}

log:
  level: INFO

metrics:
  prometheus:
    addEntryPointsLabels: true
    addServicesLabels: true
    buckets: [0.1,0.3,1.2,5.0]

ping:
  entryPoint: web
```

### Puertos Expuestos
- **80**: HTTP (redirige a HTTPS)
- **443**: HTTPS (tr√°fico principal)
- **8080**: Dashboard de Traefik

## ÔøΩüìñ Concepto Clave: Independencia de Servicios

Cada microservicio es independiente. Puedes cambiar, arreglar o mejorar el c√≥digo de un servicio sin necesidad de tocar, detener o reconstruir ning√∫n otro servicio, incluido el gateway.

-----

## üõ†Ô∏è Flujo de Trabajo para Modificar un Servicio

Sigue estos pasos para aplicar cambios en el c√≥digo de cualquier servicio (por ejemplo, `userservice`).

### Paso 1: Realiza tus Cambios en el C√≥digo

Edita los archivos de c√≥digo fuente del servicio que quieras modificar. Por ejemplo, si quieres cambiar c√≥mo se autentica un usuario, editar√≠as los archivos dentro de la carpeta `userservice/app/`.

> **Ejemplo**: Modificar `userservice/app/crud.py` para a√±adir una nueva funci√≥n.

### Paso 2: Reconstruye y Reinicia el Servicio Espec√≠fico

Una vez que hayas guardado tus cambios, necesitas decirle a Docker que reconstruya la imagen de ese servicio espec√≠fico con el nuevo c√≥digo y que reinicie el contenedor.

Abre tu terminal en la ra√≠z del proyecto y ejecuta el siguiente comando, reemplazando `<nombre-del-servicio>` por el servicio que modificaste:

```bash
docker-compose up -d --build <nombre-del-servicio>
```

  * `--build`: Le dice a Docker que reconstruya la imagen desde su `Dockerfile`.
  * `-d`: Ejecuta los contenedores en segundo plano (detached mode).

**Ejemplos pr√°cticos:**

  * Para aplicar cambios en el **servicio de usuarios**:
    ```bash
    docker-compose up -d --build userservice
    ```
  * Para aplicar cambios en el **servicio de m√∫sica**:
    ```bash
    docker-compose up -d --build music-service
    ```
  * Para aplicar cambios en el **frontend**:
    ```bash
    docker-compose up -d --build frontend
    ```

Docker ser√° lo suficientemente inteligente como para reconstruir solo el servicio que especificaste y reiniciar √∫nicamente los contenedores necesarios. El API Gateway detectar√° autom√°ticamente el nuevo contenedor actualizado y comenzar√° a enviarle tr√°fico. **No necesitas hacer nada m√°s.**

-----

## ‚ö†Ô∏è ¬øCu√°ndo S√ç se debe modificar la configuraci√≥n del Gateway?

La √∫nica vez que necesitas pensar en el API Gateway es cuando cambias el "**contrato**" de un servicio, es decir, su direcci√≥n o ruta p√∫blica. Esto se hace modificando las `labels` en el archivo `docker-compose.yml`.

**Solo necesitas actualizar `docker-compose.yml` si vas a:**

1.  **Cambiar una ruta p√∫blica**: Por ejemplo, si decides que el login ya no estar√° en `/api/users/auth/token` sino en `/auth/token`.
2.  **Cambiar el puerto interno** de un servicio.
3.  **A√±adir un nuevo microservicio** que necesite ser accesible desde el exterior.

En esos casos, simplemente ajustas las `labels` del servicio correspondiente en `docker-compose.yml` y ejecutas `docker-compose up -d`. Traefik detectar√° los cambios y actualizar√° sus reglas de enrutamiento autom√°ticamente.

## üöÄ C√≥mo Agregar un Nuevo Servicio al API Gateway

Si necesitas agregar un nuevo servicio (por ejemplo, `searchservice`), sigue estos pasos:

### 1. Define el servicio en `docker-compose.yml`

```yaml
searchservice:
  build:
    context: ./searchservice
    dockerfile: Dockerfile
  container_name: musicshare-searchservice
  restart: unless-stopped
  environment:
    PORT: 8084
  networks:
    - backend_net
  labels:
    - "traefik.enable=true"
    - "traefik.http.routers.searchservice.rule=PathPrefix(`/api/search`)"
    - "traefik.http.middlewares.searchservice-stripprefix.stripprefix.prefixes=/api/search"
    - "traefik.http.routers.searchservice.middlewares=searchservice-stripprefix"
    - "traefik.http.services.searchservice.loadbalancer.server.port=8084"
    - "traefik.http.routers.searchservice.entrypoints=websecure"
    - "traefik.http.routers.searchservice.tls=true"
```

### 2. Explica las Labels de Traefik

- **`traefik.enable=true`**: Habilita el servicio para ser descubierto por Traefik
- **`traefik.http.routers.[nombre].rule`**: Define la regla de enrutamiento (PathPrefix, Host, etc.)
- **`traefik.http.middlewares.[nombre]-stripprefix`**: Elimina el prefijo de la URL antes de reenviarla al servicio
- **`traefik.http.services.[nombre].loadbalancer.server.port`**: Puerto interno del contenedor
- **`traefik.http.routers.[nombre].entrypoints`**: Punto de entrada (web=HTTP, websecure=HTTPS)
- **`traefik.http.routers.[nombre].tls=true`**: Habilita TLS/SSL

### 3. Levanta el servicio

```bash
docker-compose up -d searchservice
```

Traefik detectar√° autom√°ticamente el nuevo servicio y comenzar√° a enrutar el tr√°fico.

## üîç Monitoreo y Debugging

### Acceder al Dashboard de Traefik
```
http://localhost:8080
```

El dashboard muestra:
- Todos los routers configurados
- Servicios activos y su estado
- Middlewares aplicados
- M√©tricas de tr√°fico en tiempo real

### Ver logs de Traefik
```bash
docker logs musicshare_traefik -f
```

### Verificar que un servicio est√° registrado
```bash
docker logs musicshare_traefik | grep "Creating service"
```

## üß† M√©tricas y Observabilidad (Versi√≥n Simplificada)

Stack m√≠nimo adoptado para reducir complejidad:

- Traefik expone m√©tricas Prometheus en `:8080/metrics`.
- Prometheus las scrapea cada 10s (ver `prometheus/prometheus.yml`).
- Grafana consume un √∫nico datasource Prometheus (UID sugerido dashboard: `ms-trfk-lb-20251117`).

Levantar:
```powershell
docker compose up -d traefik prometheus grafana
start http://localhost:3010
```

Consultas recomendadas:
- Throughput total: `sum(rate(traefik_entrypoint_requests_total[1m]))`
- Latencia p95: `histogram_quantile(0.95, sum(rate(traefik_service_request_duration_seconds_bucket[5m])) by (le))`
- Errores 5xx por servicio: `sum by(service) (increase(traefik_service_requests_total{code=~"5.."}[5m]))`
- Distribuci√≥n por router: `sum by(router) (rate(traefik_router_requests_total[1m]))`

Para pruebas manuales de carga usar `scripts/load-test.ps1`.

## üìä Resumen de Configuraci√≥n Actual

| Servicio | Ruta P√∫blica | Puerto Interno | Strip Prefix | R√©plicas | Estado |
|----------|--------------|----------------|--------------|----------|--------|
| UserService | `/api/users` | 8002 | ‚úÖ | 2 | ‚úÖ Configurado + LB |
| MusicService | `/api/music` | 8081 | ‚úÖ | 2 | ‚úÖ Configurado + LB |
| SocialService | `/api/social` | 8083 | ‚úÖ | 2 | ‚úÖ Configurado + LB |
| NotificationService | `/api/notifications` | 8082 | ‚úÖ | 2 | ‚úÖ Configurado + LB |
| NotificationService WS | `/ws` | 8082 | ‚ùå | 2 | ‚úÖ Configurado + LB |
| Next.js SSR | `/upload` | 3000 | ‚ùå | 1 | ‚úÖ Configurado |
| Formulario Post | `/formulario-post` | 80 | ‚úÖ | 1 | ‚úÖ Configurado |
| Frontend React | `/` | 80 | ‚ùå | 1 | ‚úÖ Configurado |
| SearchService | `/api/search` | - | - | - | ‚ùå No implementado |
| MetadataService | - | 50051 (gRPC) | - | 1 | üîí Interno (correcto) |

**Leyenda**: LB = Load Balancing (Balanceo de Carga) activo

---

## ‚öñÔ∏è Balanceo de Carga y Escalado Horizontal

### üéØ Descripci√≥n

MusicShare implementa **balanceo de carga autom√°tico** mediante Traefik para distribuir el tr√°fico entre m√∫ltiples r√©plicas de cada microservicio. Esto permite:

- **Alta disponibilidad**: Si una r√©plica falla, las otras contin√∫an sirviendo peticiones
- **Escalabilidad horizontal**: Aumenta la capacidad agregando m√°s r√©plicas
- **Mejor rendimiento**: Distribuye la carga entre m√∫ltiples instancias

### üîß Configuraci√≥n de R√©plicas

Los servicios backend est√°n configurados con **2 r√©plicas por defecto**:

```yaml
deploy:
  replicas: 2  # N√∫mero inicial de r√©plicas
  resources:
    limits:
      cpus: '0.5'
      memory: 512M
    reservations:
      cpus: '0.25'
      memory: 256M
  restart_policy:
    condition: on-failure
    delay: 5s
    max_attempts: 3
```

### üîÑ Algoritmo de Balanceo

Traefik utiliza **Round Robin** por defecto:
1. Primera petici√≥n ‚Üí R√©plica 1
2. Segunda petici√≥n ‚Üí R√©plica 2
3. Tercera petici√≥n ‚Üí R√©plica 1
4. Y as√≠ sucesivamente...

### üç™ Sticky Sessions

Para servicios con estado (como sesiones de usuario), se configuran **sticky sessions** mediante cookies:

```yaml
labels:
  - "traefik.http.services.userservice.loadbalancer.sticky.cookie=true"
  - "traefik.http.services.userservice.loadbalancer.sticky.cookie.name=userservice_session"
```

Esto asegura que un usuario siempre se conecte a la misma r√©plica durante su sesi√≥n.

### üíì Health Checks

Traefik verifica la salud de cada r√©plica autom√°ticamente:

```yaml
labels:
  - "traefik.http.services.userservice.loadbalancer.healthcheck.path=/health"
  - "traefik.http.services.userservice.loadbalancer.healthcheck.interval=10s"
```

Si una r√©plica falla el health check, Traefik deja de enviarle tr√°fico hasta que se recupere.

### üìà Escalar Servicios Manualmente

#### Usando Docker Compose

```powershell
# Escalar un servicio espec√≠fico a N r√©plicas
docker compose up -d --scale userservice=3 --no-recreate

# Escalar m√∫ltiples servicios
docker compose up -d --scale userservice=3 --scale music-service=4 --no-recreate
```

#### Usando el Script de Escalado

MusicShare incluye un script PowerShell para facilitar el escalado:

```powershell
# Escalar un servicio espec√≠fico
.\scripts\scale-service.ps1 -Service userservice -Replicas 5

# Escalar todos los servicios backend
.\scripts\scale-service.ps1 -Service all -Replicas 3

# Opciones disponibles:
# -Service: userservice, music-service, social-service, notificationservice, all
# -Replicas: 1-10 (n√∫mero de r√©plicas deseadas)
```

**Caracter√≠sticas del script**:
- ‚úÖ Validaci√≥n de par√°metros
- ‚úÖ Muestra estado de r√©plicas en tiempo real
- ‚úÖ Verifica salud de Traefik
- ‚úÖ Salida con colores para mejor legibilidad

### üß™ Probar el Balanceo de Carga

Utiliza el script de prueba de carga incluido:

```powershell
# Probar el balanceo en UserService con 20 peticiones
.\scripts\load-test.ps1 -Service userservice -Requests 20 -Delay 500

# Probar MusicService con 50 peticiones
.\scripts\load-test.ps1 -Service music-service -Requests 50 -Delay 200

# Par√°metros:
# -Service: userservice, music-service, social-service
# -Requests: n√∫mero de peticiones a realizar
# -Delay: milisegundos entre peticiones
```

**El script mostrar√°**:
- ‚úÖ Estado de cada petici√≥n
- ‚úÖ Tiempos de respuesta (promedio, m√≠n, m√°x)
- ‚úÖ Distribuci√≥n de carga entre r√©plicas
- ‚úÖ Porcentaje de peticiones por r√©plica

### üìä Monitoreo en Tiempo Real

Accede al dashboard de Traefik para ver el balanceo en acci√≥n:

```
http://localhost:8080/dashboard/
```

En el dashboard podr√°s ver:
- **HTTP Routers**: Reglas de enrutamiento activas
- **HTTP Services**: R√©plicas activas de cada servicio
- **Health Checks**: Estado de salud de cada r√©plica
- **Load Balancer**: Distribuci√≥n de tr√°fico

### üéØ L√≠mites de Recursos

Cada r√©plica tiene l√≠mites definidos para evitar el consumo excesivo:

| Servicio | CPU Reservada | CPU L√≠mite | RAM Reservada | RAM L√≠mite |
|----------|---------------|------------|---------------|------------|
| UserService | 0.25 | 0.5 | 256MB | 512MB |
| MusicService | 0.5 | 0.75 | 512MB | 768MB |
| SocialService | 0.5 | 0.75 | 512MB | 1024MB |
| NotificationService | 0.25 | 0.5 | 256MB | 512MB |

### üîÆ Escalado Autom√°tico (Futuro)

Para implementar escalado autom√°tico basado en m√©tricas:

1. **Integrar Prometheus + Grafana** para m√©tricas en tiempo real
2. **Configurar alertas** basadas en:
   - CPU > 70% ‚Üí Escalar +1 r√©plica
   - Requests/segundo > umbral ‚Üí Escalar +1 r√©plica
   - Tiempo de respuesta > 500ms ‚Üí Escalar +1 r√©plica
3. **Usar Kubernetes** para auto-scaling nativo con HPA (Horizontal Pod Autoscaler)

### üí° Ejemplo de Flujo de Escalado

```
1. Sistema en carga normal: 2 r√©plicas de UserService
2. Tr√°fico aumenta ‚Üí Detectado por m√©tricas
3. Administrador ejecuta: .\scripts\scale-service.ps1 -Service userservice -Replicas 5
4. Docker Compose crea 3 r√©plicas adicionales
5. Traefik detecta autom√°ticamente las nuevas r√©plicas
6. El tr√°fico se distribuye entre las 5 r√©plicas
7. Cuando la carga disminuye, se reduce a 2 r√©plicas nuevamente
```

### üö® Consideraciones Importantes

1. **Servicios con estado**: Aseg√∫rate de usar sticky sessions o almacenamiento compartido
2. **Bases de datos**: No escales las bases de datos con este m√©todo (requiere replicaci√≥n espec√≠fica)
3. **Vol√∫menes compartidos**: Los uploads deben estar en volumen compartido para todas las r√©plicas
4. **Conexiones de BD**: Cada r√©plica abre sus propias conexiones, considera el pool de conexiones

---

## üéØ Recomendaciones

### ‚úÖ Configuraci√≥n Correcta
1. **Todos los servicios REST p√∫blicos** est√°n correctamente expuestos a trav√©s del API Gateway
2. **Redirecci√≥n HTTP ‚Üí HTTPS** configurada correctamente
3. **Strip prefix** aplicado adecuadamente para mantener APIs limpias
4. **Prioridades** bien definidas (frontend como catch-all con prioridad 1)
5. **MetadataService como servicio interno** es la decisi√≥n correcta arquitect√≥nicamente
6. **Balanceo de carga activo** para servicios backend con 2 r√©plicas iniciales
7. **Health checks configurados** para monitoreo autom√°tico de r√©plicas
8. **Sticky sessions habilitadas** para mantener estado de sesi√≥n
9. **L√≠mites de recursos definidos** para prevenir consumo excesivo

### üîÑ Escalabilidad Implementada
1. **UserService, MusicService, SocialService y NotificationService** son escalables horizontalmente
2. **Scripts de automatizaci√≥n** incluidos para facilitar operaciones de escalado
3. **Pruebas de carga** disponibles para verificar el balanceo
4. **Round Robin** como algoritmo de balanceo por defecto
5. **M√©tricas de Prometheus** habilitadas para monitoreo avanzado

### üöÄ Acciones Recomendadas
1. **SearchService**: Implementar el servicio y luego agregarlo al API Gateway con la ruta `/api/search`
2. **Certificados SSL**: En producci√≥n, configurar certificados v√°lidos en `./traefik/certs`
3. **Dashboard en producci√≥n**: Cambiar `insecure: true` a `insecure: false` y configurar autenticaci√≥n
4. **Monitoreo avanzado**: Integrar Grafana para visualizaci√≥n de m√©tricas de Prometheus
5. **Auto-scaling**: Considerar migraci√≥n a Kubernetes para escalado autom√°tico basado en m√©tricas

### üîê Seguridad
- ‚úÖ Sticky sessions implementadas para mantener sesiones de usuario
- ‚ö†Ô∏è Considerar agregar middleware de rate limiting por IP
- ‚ö†Ô∏è Implementar autenticaci√≥n en el dashboard de Traefik para producci√≥n
- ‚úÖ CORS configurado en cada servicio individualmente
- ‚ö†Ô∏è Usar certificados SSL v√°lidos (Let's Encrypt o certificados corporativos) en producci√≥n
- ‚úÖ Health checks protegen contra env√≠o de tr√°fico a instancias no saludables

### üìà Rendimiento
- ‚úÖ Balanceo de carga distribuye tr√°fico entre r√©plicas
- ‚úÖ M√∫ltiples r√©plicas mejoran throughput
- ‚úÖ Health checks autom√°ticos evitan enviar tr√°fico a servicios ca√≠dos
- ‚ö†Ô∏è Considerar cach√© distribuido (Redis) para datos frecuentes
- ‚ö†Ô∏è Monitorear tiempos de respuesta y ajustar n√∫mero de r√©plicas seg√∫n carga

---

*√öltima actualizaci√≥n: 17 de noviembre de 2025*