# RetoFit 2.0 üèãÔ∏è‚Äç‚ôÇÔ∏è

Bienvenido al repositorio oficial del proyecto RetoFit 2.0. Este es un monorepo que contiene la aplicaci√≥n completa, incluyendo el frontend (con arquitectura de microfrontends) y todos los microservicios del backend.

## üèóÔ∏è Arquitectura de Microfrontends

El proyecto ahora implementa una **arquitectura de microfrontends** que separa:

- **Landing Page** (`/landing-page`) - Puerto 3001
  - P√°gina de aterrizaje p√∫blica
  - Presentaci√≥n del producto
  - Informaci√≥n del equipo
  
- **Frontend Principal** (`/front`) - Puerto 3000
  - Aplicaci√≥n completa con autenticaci√≥n
  - Dashboard, retos, perfil
  - Panel de administraci√≥n

üìñ **Documentaci√≥n detallada**: Ver [MICROFRONTENDS.md](./MICROFRONTENDS.md)

## Equipo

### Nombre del equipo
<div style="font-size: 24px"><center><p><strong> RetoFit Team </strong></p></center></div>

### Miembros:
- **Cristhian Alejandro Alarc√≥n Florido** (calarconf@unal.edu.co)
- **Andres David Caro Mora** (ancarom@unal.edu.co)
- **Anderson Steven Mateus Lopez** (amateusl@unal.edu.co)
- **Anderson David Morales Chila** (amoralesch@unal.edu.co)
- **Daniel Alejandro Ochoa Ruiz** (daochoar@unal.edu.co)
- **Cristian David Machado Guzm√°n** (cmachado@unal.edu.co)

## Sistema de Software

### Nombre
<div align="center"><h3><strong> RetoFit </strong></h3>
<img height="250px" width="250px" src="https://raw.githubusercontent.com/RetoFit/Image_Repository/refs/heads/main/svg-export-4x.png" alt="Logo"></div>

### üìú Descripci√≥n

RETOFIT es una plataforma dise√±ada para ayudar y hacer un seguimiento a los ejercicios f√≠sicos de un usuario. Adem√°s, se intenta incentivar un mayor ejercicio f√≠sico con retos, logros y la creaci√≥n de comunidades. La arquitectura est√° basada en microservicios para garantizar la escalabilidad y mantenibilidad del sistema.

## üíª Pila Tecnol√≥gica

-   **Frontend:** [Next.js](https://nextjs.org/) (React Framework)
-   **Backend:** 
    - [Python](https://www.python.org/) + [FastAPI](https://fastapi.tiangolo.com/).
    - Go.
    - Node.js.
    - PHP.
    - Java.
-   **Arquitectura:** Microservicios

## Requisitos funcionales y no funcionales

### Requisitos funcionales
---
- **RF-1:** Registrar nuevos usuarios mediante correo electr√≥nico, redes sociales o autenticaci√≥n federada (OAuth2, Google, Facebook).
- **RF-2:** Permitir login seguro y recuperaci√≥n de contrase√±a.
- **RF-3:** Gestionar perfiles (edad, peso, altura, nivel de condici√≥n f√≠sica).
- **RF-4:** Guardar historial de entrenamientos y m√©tricas de progreso.
- **RF-5:** Crear y unirse a retos individuales o grupales.
- **RF-6:** Notificar avances, asignar puntos y medallas por logros alcanzados.
- **RF-7:** Registrar actividades f√≠sicas manualmente.
- **RF-8:** Permitir compartir/publicar logros.
- **RF-9:** Permitir interacci√≥n b√°sica (likes, comentarios en logros).
- **RF-10:** Administraci√≥n de contenidos (retos oficiales, banners de campa√±as).
- **RF-11:** Monitoreo de estad√≠sticas de uso (usuarios activos, actividades registradas).

### Requisitos no funcionales
---
- **RNF-1:** Integrar autenticaci√≥n con JWT.
- **RNF-2:** Generar token seguro de recuperaci√≥n (con expiraci√≥n).
- **RNF-3:** Asegurar que las rutas /login y /password/* solo funcionen sobre HTTPS.
- **RNF-4:** A√±adir seguridad: solo el usuario due√±o puede editar/consultar su perfil.
- **RNF-5:** Validar consistencia de datos antes de guardarlos (ej. duraci√≥n > 0, fecha v√°lida).
- **RNF-6:** Validar que un usuario no se pueda unir dos veces al mismo reto. 
- **RNF-7:** Definir reglas para asignaci√≥n de puntos (ej. 10 puntos por cada actividad registrada, 50 por completar un reto).
- **RNF-8:** Definir reglas para asignaci√≥n de medallas (ej. medalla por primer reto completado, medalla por 100 km acumulados).
- **RNF-9:** Implementar validaciones de fechas para la activaci√≥n de retos y banners.
- **RNF-10:** El software debe seguir una arquitectura distribuida.
- **RNF-11:** El software debe incluir al menos dos componentes diferentes de tipo presentaci√≥n.
- **RNF-12:** El front-end web debe seguir una subarquitectura SSR (Server-Side Rendering).
- **RNF-13:** El software debe incluir al menos 4 componentes de tipo l√≥gico.
- **RNF-14:** El software debe incluir al menos un componente que permita la comunicaci√≥n/orquestaci√≥n entre los componentes l√≥gicos.
- **RNF-15:** El software debe incluir al menos 4 componentes del tipo de datos (incluyendo bases de datos relacionales y no relacionales).
- **RNF-16:** El software debe incluir al menos un componente que sea responsable de manejar procesos asincr√≥nicos dentro del sistema.
- **RNF-17:** El software debe incluir al menos dos tipos diferentes de conectores basados en HTTP.
- **RNF-18:** El software debe construirse usando al menos 5 lenguajes de programaci√≥n diferentes de proposito general.
- **RNF-19:** El despliegue del software debe ser orientado a contenedores.

## Estructura arquitect√≥nica
### Estructura de componentes y conectores
---
#### C&C View
![Diagrama de Componentes](diagramas/Diagrama_Componentes.png)

#### **Estilos y patrones arquitect√≥nicos usados**

#### Estilos arquitect√≥nicos


El estilo arquitect√≥nico usado es el de ***microservicios*** ya que el sistema de software se divide en peque√±os servicios o componentes de backend con una responsabilidad y funci√≥n espec√≠ficas. Consta de 6 de estos microservicios que se describiran m√°s adelante.

#### Patrones arquitect√≥nicos

El principal patr√≥n usado fue el ***api gateway***, el cual consiste en que desde el exterior del sistema solo hay un √∫nico punto de acceso, que en este caso es el ***api gateway***.

#### **Elementos y relaciones arquitect√≥nicas**
Consta de 15 componentes y 16 conectores. En este caso, se tienen 2 componentes de presentaci√≥n:

- **Frontend web:**

    Interfaz gr√°fica del sistema que se usa desde el navegador web.

- **Frontend m√≥vil:**

    Interfaz gr√°fica del que se usa espec√≠ficamente desde dispositivos moviles. Por ende, esta mejor optimizada para estos dispositivos.

Adicionalmente, se tiene un componente de comunicaci√≥n:

- **Api Gateway**:

    √önico punto de entrada al sistema desde el exterior, encargado de enrutar al microservicio al que se le ha pedido la solicitud. Tambi√©n, ayuda en la enrutaci√≥n dentro del sistema cuando algunos servicios necesitan informaci√≥n de otros.

Tiene 6 componentes de l√≥gica de negocio:

- **Auth:** 
    
    Este microservicio se encarga del registro, autenticaci√≥n y autorizaci√≥n (login) del sistema.

- **Users:**

    Se encarga de la gesti√≥n de la base de datos de usuarios. En √©l, se registran y modifican los perfiles de los usuarios que tenga el sistema.

- **Physical_activities:**

    Se encarga de registrar las actividades f√≠sicas (como correr, ciclismo, caminar) de los usuarios registrados en el sistema.

- **Admin:**

    Se encarga de suspender o eliminar usuarios, ver las estad√≠sticas de estos (por ejemplo, cu√°ntos hay, qu√© condici√≥n f√≠sica tienen, su g√©nero, etc). Tambi√©n, es el encargado de crear y mostrar los retos dentro de la plataforma.

- **Gamification:**

    Se encarga de asignar y calcular los puntos, de acuerdo a la actividad del usuario dentro del sistema.

- **Posts:**

    Servicio encargado de las publicaciones de los usuarios, asi como la interacci√≥n entre ellos (me gusta y responder).

A su vez cada componente de l√≥gica de negocio tiene su base de datos, es decir que hay 6 componentes de datos.

- **retofit_auth_db:**

    Tiene la informaci√≥n de las cuentas de los usuarios como el correo y la contrase√±a.

- **retofit_users_db:**

    Tiene la informaci√≥n de los perfiles de los usuarios con datos como la edad, estado f√≠sico, deporte favorito, etc.

- **retofit_activities_db:**

    Tiene la informaci√≥n de las actividades f√≠sicas realizadas por el usuarrio como los kil√≥metros recorridos y en cu√°nto tiempo los recorri√≥.

- **retofit_retos_db:**

    Tiene la informaci√≥n de todos los retos creados por el administrador, asi como el porcentaje de avance de los usuarios.

- **retofit_gamification_db:**

    Tiene los puntos que tiene cada usuario por la realizaci√≥n de actividades.

- **retofit_posts_db:**

    Contiene la informaci√≥n relacionada al contenido de los posts, ya sea el texto escrito o la imagen compartida. Adem√°s de los *me gusta* y las respuestas hechas a cada post.

En cuanto a los conectores, existen los siguientes: 

- **HTTP:**

    Conecta directamente el navegador con el frontend web.

- **Rest:**

    Existen 8 de estos conectores dentro del sistema, de los cuales 2 se utilizan para comunicarse los dos componentes de presentaci√≥n con el ***Api Gateway***, y los 6 restantes para la comunicaci√≥n entre el ***api gateway*** y cada uno de los microservicios.

- **TCP:** 

    Los conectores TCP, se usaron para comunicar cada microservicio con su base de datos. Cada lenguaje utiliz√≥ su propio controlador para la respectiva base de datos.

- **gRPC:**

    Este conector se utiliz√≥ para realizar una petici√≥n desde el microservicio ***Physical_activities*** directamente hacia el microservicio ***Users***. Esto se hiz√≥ para confirmar que el usuario exista realmente en la base de datos.


---

## Layered View
![Diagrama de Capas](diagramas/Diagrama_capas_general.png)

### Capa de Presentaci√≥n (Presentation Layer)

Es la interfaz con la que interact√∫a el usuario final. Se compone de las aplicaciones cliente que consumen la API.

* **Front web (Next.js):** Aplicaci√≥n web principal, construida con Next.js.
* **Front mobil (...):** Aplicaci√≥n m√≥vil (iOS/Android).

### API Gateway

Act√∫a como el **punto de entrada √∫nico** (Single Point of Entry) para todas las peticiones que vienen de la Capa de Presentaci√≥n. Sus responsabilidades principales incluyen:

* **Enrutamiento:** Redirige las peticiones al microservicio correspondiente en la Capa de Servicios.
* **Agregaci√≥n:** Puede combinar respuestas de m√∫ltiples servicios en una sola.
* **Gesti√≥n Transversal:** Maneja tareas comunes como la autenticaci√≥n inicial, el balanceo de carga y la limitaci√≥n de tasa (rate limiting).

### Capa de Servicios (Services Layer)

El n√∫cleo de la l√≥gica de negocio de la aplicaci√≥n. Est√° dividida en microservicios independientes, cada uno enfocado en una √∫nica responsabilidad de negocio.

* **Auth:** Maneja la autenticaci√≥n (inicio de sesi√≥n, registro, gesti√≥n de tokens).
* **User:** Gestiona toda la informaci√≥n y operaciones relacionadas con los perfiles de usuario.
* **Activities:** Administra las actividades que los usuarios realizan.
* **Posts:** Se encarga de las publicaciones (crear, leer, actualizar, borrar).
* **Admin:** Contiene la l√≥gica para las tareas de administraci√≥n del sistema.
* **Gamification:** Implementa la l√≥gica de ludificaci√≥n (puntos, insignias, niveles, tablas de clasificaci√≥n).

*Nota: Los servicios pueden comunicarse entre s√≠ (como se indica entre `User` y `Activities`) para operaciones que requieren datos de diferentes dominios.*

### Capa de Datos (Data Layer)

Gestiona la persistencia de los datos. Esta arquitectura sigue el patr√≥n **"Database per Service"** (Base de Datos por Servicio), lo que significa que cada microservicio es due√±o de sus propios datos y tiene su propia base de datos.

Esto asegura que los servicios est√©n desacoplados y puedan evolucionar de forma independiente. Se utilizan dos tecnolog√≠as de bases de datos:

#### Cluster PostgreSQL (SQL)

Utilizado para datos estructurados y relacionales:

* **`retofit_auth_db`** (pertenece al servicio `Auth`)
* **`retofit_users_db`** (pertenece al servicio `User`)
* **`retofit_activities_db`** (pertenece al servicio `Activities`)
* **`retofit_posts_db`** (pertenece al servicio `Posts`)
* **`retofit_retos_db`** (pertenece a un servicio de Retos, probablemente `Activities` o `Gamification`)

#### Cluster MongoDB (NoSQL)

Utilizado para datos con mayor flexibilidad, esquemas din√°micos o alta vol√∫menes de escritura, como los de ludificaci√≥n:

* **`retofit_gamification_db`** (pertenece al servicio `Gamification`)

---

#### Deployment View
<div align="center"><img width="80%" alt="image" src=diagramas/Diagrama_Despliegue_4.png /></div>

La vista de despliegue (Deployment View) de RETOFIT 2.0 ilustra la distribuci√≥n f√≠sica del sistema en contenedores Docker y servicios externos.

**Patrones arquitect√≥nicos aplicados:**

1. **Containerization Pattern**: Cada microservicio y frontend se empaqueta en un contenedor Docker independiente, garantizando portabilidad y aislamiento (RNF-19).

2. **Client-Server Pattern**: Separaci√≥n entre cliente (navegador del usuario) y servidores (Application Server y Data Server).

3. **Multi-tier Architecture**: Distribuci√≥n en tres capas f√≠sicas: Clientes, Application Server (presentaci√≥n y l√≥gica) y Data Server (persistencia).

4. **Managed Database Services**: Uso de servicios cloud (AWS RDS para PostgreSQL, Railway para MongoDB).

5. **Reverse Proxy Pattern**: Uso de Nginx como proxy inverso para manejar tr√°fico HTTPS y enrutar peticiones a los contenedores internos.

---

**Descripci√≥n de los elementos y relaciones:**

**1. Clients (Nodo de Cliente)**

**Elemento:** User (Usuario)

**Descripci√≥n:** Navegadores web en dispositivos de usuario final.

**Responsabilidades:**
- Ejecutar la aplicaci√≥n web Next.js.
- Realizar peticiones HTTP/HTTPS al Application Server.
- Renderizar interfaces de usuario.

**Relaciones:**
- **Cliente ‚Üí Application Server:** HTTP/HTTPS sobre internet (puertos 3000 y 3001).

---

**2. Application Server (Servidor de Aplicaci√≥n)**

**Descripci√≥n:** Servidor que aloja la l√≥gica de presentaci√≥n y negocio del sistema.

**Plataforma:** Contenedores Docker orquestados con Docker Compose.

**Componentes internos:**

**a) Presentation Layer**

- **Front web (Next.js)**  
  - **Contenedor:** Node.js 20  
  - **Puerto:** 3000  
  - **Responsabilidades:** Server-Side Rendering (SSR), servir assets est√°ticos, gesti√≥n de sesiones.

- **Landing Page (Next.js)**  
  - **Contenedor:** Node.js 18  
  - **Puerto:** 3001  
  - **Responsabilidades:** P√°gina de aterrizaje p√∫blica.

**b) API Gateway**

- **Contenedor:** Java 17 + Spring Cloud Gateway  
- **Puerto:** 8080  
- **Responsabilidades:**  
  - Punto √∫nico de entrada para peticiones.  
  - Enrutamiento a microservicios.  
  - Logging centralizado.  
  - Implementaci√≥n de Circuit Breaker y Rate Limiting.

**c) Service Layer**

Cada microservicio se despliega como contenedor Docker independiente:

1. **auth-service** - Python 3.11 + FastAPI (puerto 8001).  
2. **admin-service** - PHP 8.4 + Slim Framework (puerto 8006).  
3. **gamification-service** - Python 3.11 + FastAPI (puerto 8003).  
4. **user-service** - Python 3.11 + FastAPI (puerto 8004).  
5. **activities-service** - Go 1.25 + Gin Framework (puerto 8002).  
6. **post-service** - Node.js 20 + TypeScript + Prisma (puerto 8005).

**Comunicaci√≥n interna:**
- **Service-to-Service:** REST API sobre HTTP.
- **Service Discovery:** Docker Compose DNS.
- **gRPC:** Activities Service ‚Üí User Service para validaci√≥n.

**Relaciones:**
- **Application Server ‚Üí Data Server:** TCP para conexiones a bases de datos.
- **Comunicaci√≥n interna:** Red privada dentro de Docker Compose.

---

**3. Data Server (Servidor de Datos)**

**Descripci√≥n:** Infraestructura de bases de datos gestionadas en la nube.

**Plataforma:** AWS RDS y Railway.

**Componentes:**

**a) PostgreSQL Cluster (Postgres 15)**

**Proveedor:** AWS RDS

**Seguridad:**  
- Encriptaci√≥n en reposo y en tr√°nsito (SSL/TLS).  
- Security Groups limitando acceso solo desde Application Server.

**Bases de datos alojadas:**
1. **retofit_posts_db** - Posts Service (posts, likes, comments).  
2. **retofit_retos_db** - Admin Service (challenges, progress_logs).  
3. **retofit_auth_db** - Auth Service (users, tokens).  
4. **retofit_activities_db** - Activities Service (activities, activity_types).  
5. **retofit_users_db** - User Service (profiles, training_history).

**Conectores:**
- Python services ‚Üí `psycopg2`.  
- Node.js service ‚Üí `pg` via Prisma ORM.  
- PHP service ‚Üí `PDO PostgreSQL`.  
- Go service ‚Üí `pq`.

**b) MongoDB Cluster (MongoDB 6.0)**

**Proveedor:** Railway (MongoDB Atlas)

**Base de datos:**  
1. **retofit_gamification_db** - Gamification Service  
   - Colecciones: user_points, achievements, events, leaderboard.  
   - Ventaja: Esquema flexible para diferentes tipos de logros.

**Conector:**  
- Python ‚Üí `pymongo`.

**Relaciones:**  
- **Data Server ‚Üê Application Server:** TCP desde cada microservicio a su base de datos.  
- **Protocolo:** TCP/IP con SSL/TLS.  
- **Puertos:** PostgreSQL (5432), MongoDB (27017).  
- **Seguridad:** No hay acceso p√∫blico directo a las bases de datos.

---

**Flujo de comunicaci√≥n:**

```
Usuario (Navegador) ‚Üí [HTTP/HTTPS] ‚Üí Front web / Landing Page ‚Üí [REST] ‚Üí API Gateway ‚Üí 
[REST] ‚Üí Microservicio ‚Üí [TCP/SSL] ‚Üí Base de datos
```


**Comunicaci√≥n especial:**
- **Activities Service ‚Üí User Service:** gRPC.  
- **Admin Service ‚Üí Auth/User Service:** HTTP via Guzzle.

---

**Caracter√≠sticas de despliegue:**

**Escalabilidad:**  
- Aumento de r√©plicas de contenedores seg√∫n carga.  
- Ajuste de recursos por contenedor.

**Alta disponibilidad:**  
- Servicios cr√≠ticos con m√∫ltiples r√©plicas.  
- Bases de datos distribuidas en m√∫ltiples zonas.  
- Docker Compose reinicia autom√°ticamente contenedores no saludables.

**Seguridad:**  
- Redes privadas en Docker Compose.  
- Credenciales en archivos `.env`.  
- HTTPS obligatorio (RNF-3).  
- Encriptaci√≥n en bases de datos.

**Cumplimiento de requisitos:**  
- **RNF-19:** Despliegue orientado a contenedores ‚úì  
- **RNF-10:** Arquitectura distribuida ‚úì  
- **RNF-3:** HTTPS en rutas de autenticaci√≥n ‚úì

---

## Security View

Esta secci√≥n describe c√≥mo se gestionan los aspectos clave de seguridad dentro de la arquitectura de RetoFit 2.0, incluyendo amenazas, t√°cticas aplicadas y patrones arquitect√≥nicos utilizados. El prop√≥sito de este view es complementar la informaci√≥n del *Deployment View* mostrando c√≥mo se protege cada punto del sistema, desde la comunicaci√≥n externa hasta las interacciones internas entre microservicios.


### 1. Threat Model ‚Äî Security Scenarios

Este diagrama representa una visi√≥n general de los flujos de datos cr√≠ticos dentro del sistema y los puntos donde pueden aparecer amenazas relevantes.  
Incluye el recorrido que realiza un usuario desde el frontend, pasando por Nginx y el API Gateway, y llegando a los microservicios expuestos en la red privada.

El diagrama identifica amenazas comunes como:
- Manipulaci√≥n de tokens durante la comunicaci√≥n.
- Interceptaci√≥n de tr√°fico externo.
- Peticiones maliciosas hacia rutas cr√≠ticas.
- Accesos indebidos a servicios internos.

**Diagrama:**  

![Threat Model](<diagramas/threat model diagram.png>)
---

### 2. Security Tactics ‚Äî Controles Aplicados

Este diagrama muestra, desde una perspectiva arquitect√≥nica, qu√© t√°cticas de seguridad se aplican sobre cada uno de los componentes del sistema.  
El objetivo es presentar de manera clara c√≥mo se refuerza cada capa del modelo:

- Terminaci√≥n de HTTPS en Nginx.  
- Validaci√≥n y emisi√≥n de JWT en el Auth Service.  
- Filtrado y enrutamiento controlado en el API Gateway.  
- Aislamiento por redes internas para microservicios.  
- Respeto al patr√≥n ‚Äúdatabase-per-service‚Äù.

Esto complementa y ampl√≠a la informaci√≥n vista en el *Deployment View*.

**Diagrama:**  
![Security Tactics](<diagramas/security tactics diagram.png>)

---

### 3. Security Architecture Pattern ‚Äî Patrones Aplicados

Este diagrama presenta una vista de alto nivel sobre c√≥mo los componentes principales se organizan siguiendo patrones de seguridad utilizados en arquitecturas modernas.

Entre los patrones incluidos se encuentran:
- **Reverse Proxy** (Nginx recibiendo todo el tr√°fico entrante).  
- **API Gateway Pattern** para controlar el acceso a los microservicios.  
- **Separation of Concerns** al delegar autenticaci√≥n en un solo servicio.  
- **Network Segmentation** mediante redes p√∫blicas y privadas.  
- **Database-per-Service Pattern** reforzando el aislamiento de datos.

Este diagrama sirve para entender r√°pidamente c√≥mo la estructura general del sistema favorece la seguridad end-to-end.

**Diagrama:**  
![Security Architecture Pattern](<diagramas/security arquitecture pattern diagram.png>)

---

### 4. Authentication Sequence ‚Äî Flujo de Autenticaci√≥n

Este diagrama de secuencia ilustra el proceso completo desde que un usuario inicia sesi√≥n en la aplicaci√≥n web hasta que obtiene un JWT v√°lido, as√≠ como la validaci√≥n posterior del token cuando realiza solicitudes a microservicios protegidos.

El flujo cubre:
1. Env√≠o de credenciales desde el frontend.  
2. Paso por Nginx y enrutamiento por el API Gateway.  
3. Validaci√≥n de credenciales por el Auth Service.  
4. Emisi√≥n de un JWT si las credenciales son v√°lidas.  
5. Validaci√≥n posterior del token en cada request autenticada.

Este diagrama complementa otros views t√©cnicos del sistema mostrando claramente la interacci√≥n entre frontend, proxy, gateway y servicios internos en procesos sensibles.

**Diagrama:**  
![Auth Sequence](<diagramas/auth flow.png>)

### 5. HTTPS Evidence ‚Äî Deployment Security Proof

Esta secci√≥n presenta evidencia visual de que el sistema est√° funcionando efectivamente bajo HTTPS, con terminaci√≥n TLS en Nginx tal como se describe en el *Deployment View* y en las t√°cticas de seguridad previamente enumeradas.

Las capturas de pantalla demuestran:

- Que el frontend es servido mediante `https://localhost`.
- Que el navegador reconoce el certificado instalado en Nginx.
- Que la conexi√≥n es segura (üîí) y el certificado es v√°lido.
- Que no existen advertencias de contenido inseguro.
- Que el tr√°fico entre usuario ‚áÜ Nginx se encuentra cifrado.

Estas evidencias complementan el modelo de amenazas y validan la configuraci√≥n real del entorno.

**Capturas:**

1. **Indicador de conexi√≥n segura (HTTPS activo): NO LO PUDE PONER**    
   ![HTTPS Lock](<diagramas/https-lock.png>)

2. **Detalles del certificado y su validez:**  
   ![Certificate Details](diagramas/certificados_https.png)

3. **Frontend cargado correctamente bajo HTTPS:**  
   ![Frontend HTTPS](<diagramas/image.png>)

---


## Decomposition View
<div align="center"><img width="80%" alt="image" src="https://github.com/user-attachments/assets/8e98e040-9933-42a3-89da-af5e0bc062e3" /></div>


#### üé® FRONT

El **Front** representa las interfaces de usuario del sistema, permitiendo la interacci√≥n con las funcionalidades expuestas por los microservicios.

- **FRONT WEB**  
  Interfaz web desarrollada (**Next.js**) para administraci√≥n y uso general desde navegadores.

- **FRONT M√ìVIL**  
  Aplicaci√≥n m√≥vil (**Dart**) para usuarios finales.

Ambas interfaces se comunican con el **API Gateway**, que enruta las solicitudes hacia los servicios internos.


#### ‚öôÔ∏è SERVICES

El sistema est√° compuesto por varios microservicios independientes, cada uno con una responsabilidad espec√≠fica:

| Servicio | Descripci√≥n |
|-----------|--------------|
| **auth-service** | Maneja la autenticaci√≥n y autorizaci√≥n de usuarios (login, registro, tokens JWT, etc.). |
| **user-service** | Gestiona la informaci√≥n del perfil de usuario y datos personales. |
| **physical_activities_service** | Registra y consulta actividades f√≠sicas realizadas por los usuarios. |
| **posts-service** | Permite la creaci√≥n, lectura y gesti√≥n de publicaciones o retos dentro de la plataforma. |
| **admin-service** | Ofrece funcionalidades administrativas para la gesti√≥n general del sistema. |
| **gamification-service** | Administra la l√≥gica de gamificaci√≥n: puntos, niveles, recompensas y ranking de usuarios. |

Cada servicio puede ejecutarse de forma independiente y se comunica con los dem√°s a trav√©s del **API Gateway**.


#### üåê API GATEWAY

El **API Gateway** act√∫a como punto de entrada √∫nico para todas las solicitudes externas.  
Su funci√≥n principal es redirigir, filtrar y centralizar la comunicaci√≥n entre el **Front** y los distintos **microservicios**.

- Carpeta `target/`  
  Contiene el archivo compilado `api-gateway-1.0.0.0.jar`, que puede ejecutarse para iniciar el Gateway.

---
## üîí Pruebas de Patrones de Seguridad

### üõ°Ô∏è Seguridad y Segmentaci√≥n de Red

El proyecto implementa una estrategia de **defensa en profundidad** mediante segmentaci√≥n de redes en Docker. Esto asegura que los microservicios no sean accesibles directamente desde el frontend o internet, forzando todo el tr√°fico a trav√©s del API Gateway.

### Arquitectura de Redes

| Red | Tipo | Servicios Conectados | Descripci√≥n |
|-----|------|----------------------|-------------|
| **public-net** | Bridge | Nginx, Landing Page, Frontend, API Gateway | Red expuesta (v√≠a proxy) para la interfaz de usuario. |
| **private-net** | Bridge | API Gateway, Todos los Microservicios, Bases de Datos | Red aislada. Contiene la l√≥gica de negocio y datos. |

### Verificaci√≥n de Aislamiento

Se ha incluido un script automatizado para validar que las reglas de firewall de Docker est√©n funcionando correctamente.

Esto se detallar de mejor forma en el diagrama de despliegue anteriormente mostrado.

**Requisitos:**
- Python 3 instalado.
- Contenedores corriendo (`docker compose up -d`).

### Rate Limiting Pattern

El sistema implementa el patr√≥n **Rate Limiting**  utilizando **Nginx** como Reverse Proxy y de forma m√°s detallada en el api gateway usando redis. Este mecanismo protege a los microservicios situados abajo (como `auth-service` y `user-service`) de ser saturados por picos de tr√°fico o ataques de denegaci√≥n de servicio (DoS).

#### Configuraci√≥n del Patr√≥n

- **Zona de Memoria:** `apilimit` (10MB compartidos)
- **Tasa Sostenida:** 10 peticiones/segundo (`10r/s`)
- **R√°faga (Burst):** 20 peticiones
- **Comportamiento:** Las peticiones dentro de la r√°faga se procesan instant√°neamente (`nodelay`), pero si se excede la capacidad total (Tasa + R√°faga), Nginx corta la conexi√≥n inmediatamente.
- En la clase `RateLimiterConfig.Java`, se implementan 3 modos en el cual puede analizar el trafico el api gateway con redis:
    - ipKeyResolver
    - userKeyResolver
    - userIpKeyResolver (implementado por defecto)

#### Realizaci√≥n de prueba
Se tienen que ejecutar los siguientes comandos:
```bash
# Primero
cd ./testing/rate_limit/

# Segundo
kubectl apply -f prometheus.yaml

# Tercero
kubectl apply -f grafana.yaml

# Cuarto
kubectl create configmap k6-scripts --from-file=scripts/k6_rate_limit_test.js --namespace=default

# Quinto
kubectl apply -f k6-prometheus-job.yaml

# Para abrir grafana
minikube service grafana --url
```

En la interfaz de grafana:
- **Usuario:** admin
- **Contrase√±a:** admin

Luego, se escribe la constrase√±a que desea.

Despu√©s, importa un dashboard. Para *Prometheus* el **id** es ***18030***. A continuaci√≥n, se tiene que importar un data source colocando como url: *http://prometheus.default.svc.cluster.local:9090*.

#### Resultado obtenido
<div align="center"><img width="80%" alt="image" src="diagramas/resultados_test_rate_limit.png" /></div>

**Beneficios Demostrados**
1. Protecci√≥n Anti-DoS: Evita que un atacante inunde el sistema con solicitudes.

2. Estabilidad: Garantiza que los microservicios (User, Auth, etc.) solo reciban una carga de trabajo que pueden procesar.

3. Seguridad en el Borde: El tr√°fico malicioso es detenido en Nginx, antes de consumir recursos de procesamiento del API Gateway o la Base de Datos.


## üß™ Pruebas de Patrones de Escalabilidad

### Circuit Breaker Pattern

El sistema implementa el patr√≥n **Circuit Breaker** usando Spring Cloud Gateway y Resilience4j para mejorar la resiliencia y prevenir cascadas de fallos cuando un servicio est√° ca√≠do.

#### Configuraci√≥n del Circuit Breaker

- **Umbral de fallos:** 50%
- **Llamadas m√≠nimas:** 5
- **Timeout por petici√≥n:** 5 segundos
- **Tiempo en estado OPEN:** 10 segundos
- **Estados:** CLOSED ‚Üí OPEN ‚Üí HALF_OPEN ‚Üí CLOSED

#### Scripts de Prueba

Se incluyen dos scripts PowerShell para probar el Circuit Breaker:

**1. Prueba Directa al Gateway (sin Nginx)**

```powershell
.\test-circuit-breaker-direct.ps1
```

Este script prueba el Circuit Breaker accediendo directamente al API Gateway en el puerto 8081, sin pasar por Nginx.

**Resultados esperados:**
- Tiempo SIN Circuit Breaker: ~24-30 segundos (timeouts)
- Tiempo CON Circuit Breaker: ~1-2 segundos (fallback inmediato)
- **Mejora de performance: ~15-20x m√°s r√°pido**

**2. Prueba a trav√©s de Nginx (HTTPS)**

```powershell
.\test-circuit-breaker-nginx.ps1
```

Este script prueba el Circuit Breaker en un escenario real, accediendo a trav√©s de Nginx con HTTPS y Rate Limiting configurado.

**Resultados esperados:**
- Tiempo SIN Circuit Breaker: ~5-10 segundos
- Tiempo CON Circuit Breaker: ~1-2 segundos
- **Mejora de performance: ~4-5x m√°s r√°pido**

#### Monitoreo del Circuit Breaker

Puedes verificar el estado de los Circuit Breakers en tiempo real:

```powershell
# Ver todos los circuit breakers
Invoke-WebRequest -Uri http://localhost:8081/actuator/circuit-breakers -UseBasicParsing

# Ver un circuit breaker espec√≠fico
Invoke-WebRequest -Uri http://localhost:8081/actuator/circuit-breakers/usersServiceCircuitBreaker -UseBasicParsing
```

#### Endpoints de Fallback

Cuando un servicio falla y el Circuit Breaker se activa (estado OPEN), el sistema retorna autom√°ticamente respuestas de fallback con mensajes descriptivos:

```json
{
  "timestamp": "2025-11-17T03:02:23.822894950",
  "status": 503,
  "error": "Service Unavailable",
  "message": "El servicio de usuarios no est√° disponible temporalmente. Por favor, intente m√°s tarde.",
  "service": "Users Service",
  "circuitBreakerActivated": true
}
```

#### Beneficios Demostrados

1. **Resiliencia:** El sistema sigue respondiendo aunque servicios internos fallen
2. **Performance:** Respuestas inmediatas (sin esperar timeouts de 5 segundos)
3. **Auto-recuperaci√≥n:** El circuito se cierra autom√°ticamente cuando el servicio se recupera
4. **Prevenci√≥n de cascada:** Evita que fallos en un servicio tumben todo el sistema
5. **Experiencia de usuario:** Mensajes claros en lugar de timeouts largos

### Prueba de estr√©s
<div align="center"><img width="80%" alt="resultado del test de rate limit" src="diagramas/prueba_estres.png" /></div>

## Pruebas de Patrones de Escalabilidad

### Escenario 1: Replication Pattern (Patr√≥n de Replicaci√≥n)

El sistema implementa el Replication Pattern para garantizar alta disponibilidad y balanceo de carga. M√∫ltiples r√©plicas de los servicios cr√≠ticos se ejecutan simult√°neamente para distribuir la carga y proporcionar tolerancia a fallos.

#### Configuraci√≥n de R√©plicas

| Servicio | R√©plicas |
|----------|----------|
| auth-service | 2 |
| users-service | 2 |
| activities-service | 2 |
| gamification-service | 1 |
| posts-service | 1 |
| admin-service | 1 |
| api-gateway | 1 |
| frontend | 1 |
| landing-page | 1 |
| nginx-proxy | 1 |

#### Implementaci√≥n en Kubernetes

Configuraci√≥n para servicios con 2 r√©plicas:
```yaml
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
```

#### Comandos de Verificaci√≥n

```bash
# Ver r√©plicas activas
kubectl get pods -l app=auth-service -o wide

# Escalar manualmente
kubectl scale deployment auth-service --replicas=3

# Ver distribuci√≥n de carga
kubectl logs -l app=auth-service --tail=100
```

#### Script de Prueba

```bash
# Test de balanceo de carga
./k8s/test-load-balancing.sh
```

---

### Escenario 2: Service Discovery Pattern (Descubrimiento de Servicios)

El sistema implementa Service Discovery nativo de Kubernetes mediante DNS interno (CoreDNS). Cada servicio se descubre autom√°ticamente por su nombre DNS.

#### Implementaci√≥n

Servicios ClusterIP:
```yaml
apiVersion: v1
kind: Service
metadata:
  name: auth-service
spec:
  type: ClusterIP
  selector:
    app: auth-service
  ports:
  - port: 8001
    targetPort: 8001
```

Resoluci√≥n DNS:
- Nombre corto: `http://auth-service:8001`
- FQDN completo: `http://auth-service.default.svc.cluster.local:8001`

#### Comunicaci√≥n Entre Servicios

Ejemplos implementados:

1. API Gateway a Microservicios (HTTP)
```yaml
- id: auth-route
  uri: http://auth-service:8001
  
- id: users-route
  uri: http://users-service:8004
```

2. Activities Service a Users Service (gRPC)
```go
conn, err := grpc.Dial("users-service:50051", grpc.WithInsecure())
```

#### NetworkPolicy para DNS

```yaml
# k8s/05-network-policies/allow-dns.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-dns-access
spec:
  podSelector: {}
  policyTypes:
  - Egress
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    - podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 53
```

#### Verificaci√≥n

```bash
# Verificar resoluci√≥n DNS desde un pod
kubectl run test --image=busybox --rm -it --restart=Never -- nslookup auth-service
```

---

### Escenario 3: Cluster Pattern (Patr√≥n de Cluster)

El sistema se despliega en un Kubernetes Cluster que gestiona la orquestaci√≥n, distribuci√≥n y alta disponibilidad de todos los componentes.

#### Arquitectura del Cluster

```
Kubernetes Control Plane
   API Server | Scheduler | Controller Manager

Worker Node(s) - Minikube
   Pods: auth-service, users-service, activities-service
   Pods: gamification-service, posts-service, admin-service
   Pods: api-gateway, nginx-proxy, frontend, landing-page
```

#### Componentes del Cluster

Control Plane:
- API Server: Punto de entrada para todas las operaciones
- Scheduler: Asigna pods a nodos
- Controller Manager: Mantiene el estado deseado
- etcd: Base de datos del estado del cluster

Worker Nodes:
- Kubelet: Agente en cada nodo
- kube-proxy: Maneja reglas de red
- Container Runtime: Docker/containerd

#### Servicios Desplegados

```bash
# Ver todos los pods y su ubicaci√≥n
kubectl get pods -o wide
```

#### Configuraci√≥n del Cluster Local

Minikube:
```bash
# Iniciar cluster
minikube start --memory=5000 --cpus=3

# Cargar im√°genes locales
minikube image load retofit/auth-service:latest
```

#### Health Checks Implementados

Cada servicio tiene configurados health checks:

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8001
  initialDelaySeconds: 30
  periodSeconds: 10
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /health
    port: 8001
  initialDelaySeconds: 10
  periodSeconds: 5
  failureThreshold: 3
```

#### Comandos de Gesti√≥n

```bash
# Ver informaci√≥n del cluster
kubectl cluster-info

# Ver nodos
kubectl get nodes

# Ver uso de recursos
kubectl top nodes
kubectl top pods

# Ver todos los recursos
kubectl get all
```

---

### Escenario 4: Rolling Update Pattern (Actualizaci√≥n Rotativa)

El sistema implementa el **Rolling Update Pattern** para realizar actualizaciones de servicios sin tiempo de inactividad (zero downtime). Kubernetes gestiona autom√°ticamente el proceso de actualizaci√≥n gradual.

#### Estrategia de Actualizaci√≥n Configurada

**Para servicios con 2 r√©plicas:**
```yaml
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1    # M√°ximo 1 pod puede estar inactivo
      maxSurge: 1          # M√°ximo 1 pod extra durante actualizaci√≥n
```

**Significado:**
- Durante la actualizaci√≥n, puede haber hasta 3 pods (2 originales + 1 nuevo)
- Siempre hay al menos 1 pod funcionando (2 - maxUnavailable)
- Los pods se actualizan uno por uno

**Para servicios con 1 r√©plica:**
```yaml
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0    # No puede haber pods inactivos
      maxSurge: 1          # Crea el nuevo antes de eliminar el viejo
```

**Significado:**
- Primero crea el nuevo pod
- Espera a que est√© Ready (health checks)
- Luego elimina el pod viejo
- Garantiza zero downtime incluso con 1 sola r√©plica

#### Proceso de Rolling Update

**Ejemplo: Actualizar auth-service de v1 a v2**

```
Estado Inicial:
  auth-service-v1-pod1 [Running]
  auth-service-v1-pod2 [Running]

Paso 1 - Crear nuevo pod:
  auth-service-v1-pod1 [Running]
  auth-service-v1-pod2 [Running]
  auth-service-v2-pod1 [Creating]

Paso 2 - Esperar health checks:
  auth-service-v1-pod1 [Running]
  auth-service-v1-pod2 [Running]
  auth-service-v2-pod1 [Ready] (liveness + readiness OK)

Paso 3 - Eliminar pod viejo:
  auth-service-v1-pod1 [Terminating]
  auth-service-v1-pod2 [Running]
  auth-service-v2-pod1 [Running]

Paso 4 - Crear segundo pod nuevo:
  auth-service-v1-pod2 [Running]
  auth-service-v2-pod1 [Running]
  auth-service-v2-pod2 [Creating]

Paso 5 - Completado:
  auth-service-v2-pod1 [Running]
  auth-service-v2-pod2 [Running]
```

**En ning√∫n momento hay menos de 2 pods activos**

#### Comandos para Rolling Updates

**1. Actualizar imagen de servicio:**
```bash
# Construir nueva versi√≥n
docker build -t retofit/auth-service:v2 ./services/auth-service

# Cargar en minikube
minikube image load retofit/auth-service:v2

# Actualizar deployment (inicia rolling update autom√°tico)
kubectl set image deployment/auth-service auth-service=retofit/auth-service:v2
```

**2. Monitorear el rollout:**
```bash
# Ver progreso en tiempo real
kubectl rollout status deployment/auth-service

# Salida:
# Waiting for deployment "auth-service" rollout to finish: 1 out of 2 new replicas have been updated...
# Waiting for deployment "auth-service" rollout to finish: 1 old replicas are pending termination...
# deployment "auth-service" successfully rolled out
```

**3. Ver historial de versiones:**
```bash
# Ver todas las revisiones
kubectl rollout history deployment/auth-service

# Ver detalles de una revisi√≥n espec√≠fica
kubectl rollout history deployment/auth-service --revision=2
```

**4. Rollback si algo sale mal:**
```bash
# Deshacer √∫ltima actualizaci√≥n
kubectl rollout undo deployment/auth-service

# Volver a una revisi√≥n espec√≠fica
kubectl rollout undo deployment/auth-service --to-revision=1

# Pausar un rollout en progreso
kubectl rollout pause deployment/auth-service

# Resumir rollout pausado
kubectl rollout resume deployment/auth-service
```

**5. Reiniciar pods sin cambiar imagen:**
```bash
# Rolling restart (√∫til para aplicar cambios de ConfigMaps/Secrets)
kubectl rollout restart deployment/auth-service
```

#### Integraci√≥n con Health Checks

El Rolling Update respeta los health checks configurados:

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8001
  initialDelaySeconds: 30    # Espera 30s antes de verificar
  periodSeconds: 10          # Verifica cada 10s
  failureThreshold: 3        # Falla tras 3 intentos fallidos

readinessProbe:
  httpGet:
    path: /health
    port: 8001
  initialDelaySeconds: 10
  periodSeconds: 5
  failureThreshold: 3
```

**Comportamiento:**
1. Kubernetes crea el nuevo pod
2. Espera `initialDelaySeconds` 
3. Ejecuta readiness probe cada `periodSeconds`
4. Solo despu√©s de 3 √©xitos consecutivos marca el pod como Ready
5. Solo entonces elimina pods viejos
6. Si el nuevo pod falla liveness/readiness, el rollout se detiene autom√°ticamente

#### Beneficios del Rolling Update Pattern

- **Zero Downtime:** Servicio siempre disponible durante actualizaciones
- **Rollback Autom√°tico:** Si health checks fallan, Kubernetes no contin√∫a
- **Control Gradual:** Actualizaci√≥n progresiva, no todo a la vez
- **Seguridad:** Validaci√≥n con health checks antes de eliminar versi√≥n anterior
- **Historial:** Posibilidad de volver a cualquier versi√≥n anterior
- **Configurabilidad:** Control fino sobre velocidad de actualizaci√≥n

#### Ejemplo Real de Actualizaci√≥n

```bash
# Supongamos que auth-service tiene un bug en producci√≥n

# 1. Desarrollador corrige el c√≥digo y hace commit
git commit -am "Fix authentication bug"

# 2. Construir nueva imagen con tag espec√≠fico
docker build -t retofit/auth-service:v1.2.1 ./services/auth-service

# 3. Cargar en cluster
minikube image load retofit/auth-service:v1.2.1

# 4. Actualizar deployment
kubectl set image deployment/auth-service auth-service=retofit/auth-service:v1.2.1

# 5. Monitorear en tiempo real
kubectl get pods -l app=auth-service -w

# Ver√°s:
# auth-service-old-abc  1/1  Running     -> Terminating
# auth-service-new-xyz  0/1  Creating    -> Running -> Ready
# auth-service-old-def  1/1  Running     -> Terminating
# auth-service-new-uvw  0/1  Creating    -> Running -> Ready

# 6. Verificar estado final
kubectl rollout status deployment/auth-service
# deployment "auth-service" successfully rolled out

# 7. Si algo sale mal, rollback inmediato
kubectl rollout undo deployment/auth-service
```

#### Configuraci√≥n para Todos los Servicios

Servicios con Rolling Update configurado:
- auth-service (2 r√©plicas)
- users-service (2 r√©plicas)
- activities-service (2 r√©plicas)
- gamification-service (1 r√©plica)
- posts-service (1 r√©plica)
- admin-service (1 r√©plica)
- api-gateway (1 r√©plica)
- frontend (1 r√©plica)
- landing-page (1 r√©plica)
- nginx-proxy (1 r√©plica)

**Todos los deployments** tienen la estrategia `type: RollingUpdate` expl√≠citamente configurada en sus archivos YAML (`k8s/04-deployments/`).


---

## Prototipo
## üöÄ Gu√≠a de Instalaci√≥n y Ejecuci√≥n

## üìã Requisitos Previos

- **Kubernetes local**: minikube, kind, o Docker Desktop con Kubernetes habilitado
- **kubectl**: CLI de Kubernetes instalado
- **Docker**: Para construir im√°genes
- **Recursos m√≠nimos**: 8GB RAM, 4 CPU cores, 20GB disk

## üöÄ Gu√≠a de Deployment R√°pido

### Paso 1: Iniciar Cluster

**Opci√≥n A - minikube:**
```bash
minikube start --memory=8192 --cpus=4
minikube tunnel  # En terminal separada (necesario para LoadBalancer local)
```

**Opci√≥n B - Docker Desktop:**
- Settings ‚Üí Kubernetes ‚Üí Enable Kubernetes

### Paso 2: Construir Im√°genes Docker

```bash
# Desde la ra√≠z del proyecto
docker build -t retofit/auth-service:latest ./services/auth-service
docker build -t retofit/users-service:latest ./services/user-service
docker build -t retofit/activities-service:latest ./services/physical_activities_service
docker build -t retofit/gamification-service:latest ./services/gamification-service
docker build -t retofit/posts-service:latest ./services/posts-service
docker build -t retofit/admin-service:latest ./services/admin-service
docker build -t retofit/api-gateway:latest ./api_gateway_2.1
docker build -t retofit/landing-page:latest ./landing-page
docker build -t retofit/frontend:latest ./front
```

**Para minikube - cargar im√°genes:**
```bash
minikube image load retofit/auth-service:latest
minikube image load retofit/users-service:latest
minikube image load retofit/activities-service:latest
minikube image load retofit/gamification-service:latest
minikube image load retofit/posts-service:latest
minikube image load retofit/admin-service:latest
minikube image load retofit/api-gateway:latest
minikube image load retofit/landing-page:latest
minikube image load retofit/frontend:latest
```

### Paso 3: Generar Certificados TLS

**IMPORTANTE**: Antes de desplegar, debes generar certificados TLS para Nginx.

**Opci√≥n A - Usar script automatizado (Recomendado):**

```bash
# En PowerShell (Windows)
cd k8s
.\generate-certs.ps1

# En Bash (Linux/Mac/Git Bash)
cd k8s
chmod +x generate-certs.sh
./generate-certs.sh
```

**Opci√≥n B - Generar manualmente con OpenSSL:**

```bash
# Crear directorio
mkdir -p nginx/tls

# Generar clave privada
openssl genrsa -out nginx/tls/nginx-key.pem 2048

# Generar certificado autofirmado (v√°lido por 365 d√≠as)
openssl req -new -x509 -sha256 \
  -key nginx/tls/nginx-key.pem \
  -out nginx/tls/nginx.pem \
  -days 365 \
  -subj "/C=CO/ST=Cundinamarca/L=Bogota/O=RetoFit/OU=Development/CN=localhost" \
  -addext "subjectAltName=DNS:localhost,DNS:*.localhost,IP:127.0.0.1"
```

‚ö†Ô∏è **Nota**: Estos son certificados autofirmados para desarrollo. Los navegadores mostrar√°n advertencias de seguridad - esto es normal para desarrollo local.

### Paso 4: Crear Secrets

```bash
# TLS Secret (Nginx)
kubectl create secret generic nginx-tls-secret \
  --from-file=nginx.pem=./nginx/tls/nginx.pem \
  --from-file=nginx-key.pem=./nginx/tls/nginx-key.pem

# Aplicar secrets YAML
kubectl apply -f k8s/02-secrets/

# Verificar
kubectl get secrets
```

### Paso 5: Crear ConfigMaps

```bash
kubectl apply -f k8s/01-configmaps/

# Verificar
kubectl get configmaps
```

### Paso 6: Crear Services

```bash
kubectl apply -f k8s/03-services/

# Verificar
kubectl get services
```

### Paso 7: Desplegar Aplicaciones

```bash
# Backend services
kubectl apply -f k8s/04-deployments/auth-service-deployment.yaml
kubectl apply -f k8s/04-deployments/users-service-deployment.yaml
kubectl apply -f k8s/04-deployments/activities-service-deployment.yaml
kubectl apply -f k8s/04-deployments/gamification-service-deployment.yaml
kubectl apply -f k8s/04-deployments/posts-service-deployment.yaml
kubectl apply -f k8s/04-deployments/admin-service-deployment.yaml

# Esperar a que est√©n ready
kubectl wait --for=condition=ready pod -l tier=backend --timeout=180s

# API Gateway
kubectl apply -f k8s/04-deployments/api-gateway-deployment.yaml
kubectl wait --for=condition=ready pod -l app=api-gateway --timeout=180s

# Frontends
kubectl apply -f k8s/04-deployments/landing-page-deployment.yaml
kubectl apply -f k8s/04-deployments/frontend-deployment.yaml
kubectl wait --for=condition=ready pod -l tier=frontend --timeout=120s

# Nginx
kubectl apply -f k8s/04-deployments/nginx-deployment.yaml
kubectl wait --for=condition=ready pod -l app=nginx-proxy --timeout=60s
```

### Paso 8: Aplicar NetworkPolicies

```bash
kubectl apply -f k8s/05-network-policies/

# Verificar
kubectl get networkpolicies
```

### Paso 9: Verificar Deployment

```bash
# Ver todos los pods
kubectl get pods -o wide

# Ver servicios y LoadBalancer IP
kubectl get services

# Ver logs de un servicio
kubectl logs -l app=auth-service --tail=50

# Test acceso externo
curl -k https://localhost/
curl -k https://localhost/dashboard
```

## üß™ Testing y Validaci√≥n

### Test de Conectividad Backend

```bash
# Port-forward API Gateway
kubectl port-forward deployment/api-gateway 8081:8081

# Ver circuit breakers
curl http://localhost:8081/actuator/circuitbreakers

# Ver health
curl http://localhost:8081/actuator/health
```

### Test de Load Balancing

```bash
# Escalar auth-service
kubectl scale deployment auth-service --replicas=3

# Ver distribuci√≥n de pods
kubectl get pods -l app=auth-service -o wide

# Ver logs para verificar load balancing
kubectl logs -l app=auth-service --tail=100
```

### Test de gRPC (Activities ‚Üí Users)

```bash
# Ver logs de activities service
kubectl logs -l app=activities-service | grep -i "grpc\|users"

# Ver logs de users service
kubectl logs -l app=users-service | grep -i "grpc\|50051"
```

## üîí NetworkPolicies Aplicadas

1. **allow-dns.yaml**: Permite a todos los pods acceder a kube-dns
2. **allow-external-db.yaml**: Permite egress a AWS RDS (5432) y Railway MongoDB (10201)
3. **activities-to-users-grpc.yaml**: Permite gRPC entre activities y users (50051)

**Nota**: No se aplica `default-deny-all` para facilitar debugging en desarrollo.

## üõ†Ô∏è Comandos √ötiles

### Ver Estado del Cluster

```bash
# Ver todos los recursos
kubectl get all

# Ver pods con detalles
kubectl get pods -o wide

# Ver uso de recursos
kubectl top nodes
kubectl top pods

# Ver eventos
kubectl get events --sort-by='.lastTimestamp'
```

### Debugging

```bash
# Logs en tiempo real
kubectl logs -l app=auth-service -f --tail=100

# Ejecutar comando en pod
kubectl exec -it deployment/auth-service -- /bin/sh

# Port-forward para acceso local
kubectl port-forward deployment/api-gateway 8081:8081

# Describir pod (ver eventos y configuraci√≥n)
kubectl describe pod <pod-name>
```

### Escalar Servicios

```bash
# Escalar manualmente
kubectl scale deployment auth-service --replicas=3

# Ver status de escalado
kubectl get deployment auth-service

# Reiniciar deployment (rolling restart)
kubectl rollout restart deployment auth-service
kubectl rollout status deployment auth-service
```

### Gesti√≥n

```bash
# Eliminar deployment espec√≠fico
kubectl delete deployment auth-service

# Eliminar todos los deployments
kubectl delete -f k8s/04-deployments/

# Eliminar todo
kubectl delete -f k8s/
```

## üêõ Troubleshooting

### Pod en CrashLoopBackOff

```bash
# Ver logs del pod
kubectl logs <pod-name>

# Ver eventos
kubectl describe pod <pod-name>

# Causas comunes:
# - DATABASE_URL incorrecta
# - Secret no existe
# - Puerto incorrecto en containerPort
```

### ImagePullBackOff

```bash
# Verificar imagen existe
docker images | grep retofit

# Cargar imagen en minikube
minikube image load retofit/<service-name>:latest

# Verificar imagePullPolicy en deployment
kubectl get deployment <name> -o yaml | grep imagePullPolicy
```

### Service No Alcanzable

```bash
# Verificar endpoints
kubectl get endpoints <service-name>

# Si no hay endpoints, verificar selector
kubectl get pods --show-labels
kubectl describe svc <service-name>

# Test desde otro pod
kubectl run test --image=curlimages/curl --rm -it --restart=Never -- \
  curl -v http://<service-name>:<port>/
```

### LoadBalancer Pending

**Para minikube:**
```bash
# Ejecutar en terminal separada
minikube tunnel
```

**Para kind:**
Requiere MetalLB o configuraci√≥n de port mapping al crear cluster.

**Para Docker Desktop:**
Autom√°tico, verificar que puerto no est√© en uso.

## üìà Monitoring

### Metrics Server (Opcional)

```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Ver m√©tricas
kubectl top nodes
kubectl top pods
```

### Kubernetes Dashboard (Opcional)

```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml

# Crear token de acceso
kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard
kubectl create clusterrolebinding dashboard-admin \
  --clusterrole=cluster-admin \
  --serviceaccount=kubernetes-dashboard:dashboard-admin

# Get token
kubectl create token dashboard-admin -n kubernetes-dashboard

# Proxy
kubectl proxy

# Acceder: http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/
```
Tambi√©n, se puede usar
```bash
minikube dashboard
```
## üîÑ Actualizar Aplicaciones

```bash
# Rebuild imagen
docker build -t retofit/auth-service:v2 ./services/auth-service

# Cargar en cluster
minikube image load retofit/auth-service:v2

# Actualizar deployment
kubectl set image deployment/auth-service auth-service=retofit/auth-service:v2

# Ver rollout
kubectl rollout status deployment/auth-service
```

## Despliegue
**Link:** https://34.69.186.15

---

## üìÅ Estructura del Proyecto

```
RETOFIT_2.0/
‚îú‚îÄ‚îÄ api_gateway_2.1/            # Api Gateway (Java + Spring Cloud Gateway)
‚îÇ   ‚îú‚îÄ‚îÄ src/
|   |   ‚îî‚îÄ‚îÄ main/ 
|   |       ‚îú‚îÄ‚îÄ java/
|   |       |   ‚îî‚îÄ‚îÄ com/
|   |       |       ‚îî‚îÄ‚îÄ example/
|   |       |           ‚îî‚îÄ‚îÄ api_gateway/
|   |       |               ‚îú‚îÄ‚îÄ config/
|   |       |               |   ‚îú‚îÄ‚îÄ CorsConfig.java
|   |       |               |   ‚îî‚îÄ‚îÄ CircuitBreakerConfig.java
|   |       |               ‚îú‚îÄ‚îÄ filter/
|   |       |               |   ‚îî‚îÄ‚îÄ LoggingFilter.java
|   |       |               ‚îî‚îÄ‚îÄ Application.java
‚îÇ   |       ‚îî‚îÄ‚îÄ resources/
|   |           ‚îî‚îÄ‚îÄ application.yml
‚îÇ   ‚îú‚îÄ‚îÄ pom.xml
‚îú‚îÄ‚îÄ landing-page/              # üÜï Landing Page Microfrontend (Next.js - Puerto 3001)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/              # App Router
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx     # P√°gina principal
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx   # Layout ra√≠z
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ globals.css  # Estilos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/      # Componentes UI
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ui/         # shadcn/ui
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ icons.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lib/            # Utilidades
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ images/         # Im√°genes del equipo
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile          # Multi-stage build
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ next.config.ts
‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.ts
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ front/                     # Frontend Principal (Next.js - Puerto 3000)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/              # App Router
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ (auth)/      # Rutas de autenticaci√≥n
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dashboard/   # Dashboard
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ admin/       # Panel admin
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/      # Componentes React
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/          # Custom hooks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib/            # APIs y utilidades
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ai/             # Integraci√≥n Genkit
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ next.config.ts
‚îú‚îÄ‚îÄ nginx/                     # Reverse Proxy
‚îÇ   ‚îú‚îÄ‚îÄ nginx.conf            # Configuraci√≥n de enrutamiento
‚îÇ   ‚îî‚îÄ‚îÄ tls/                  # Certificados SSL
‚îú‚îÄ‚îÄ services/                  # Microservicios Backend
|    ‚îú‚îÄ‚îÄ auth-service/          # (Python + FastAPI) Puerto 8001
|    ‚îú‚îÄ‚îÄ admin-service/         # (PHP + Slim) Puerto 8006
|    ‚îú‚îÄ‚îÄ gamification-service/  # (Python + FastAPI) Puerto 8003
|    ‚îú‚îÄ‚îÄ physical_activities_service/  # (Go + Gin) Puerto 8002
|    ‚îú‚îÄ‚îÄ posts-service          # (Node.js + TypeScript) Puerto 8005
|    ‚îî‚îÄ‚îÄ user-service/          # (Python + FastAPI) Puerto 8004
‚îú‚îÄ‚îÄ k8s/
‚îú‚îÄ‚îÄ docker-compose.yaml        # Orquestaci√≥n de contenedores
‚îú‚îÄ‚îÄ microfrontends.ps1         # üÜï Script de gesti√≥n de microfrontends
‚îú‚îÄ‚îÄ MICROFRONTENDS.md          # üÜï Documentaci√≥n de arquitectura
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Gu√≠a de Inicio R√°pido

### Requisitos Previos

- **Docker** y **Docker Compose** instalados
- **Node.js** 18+ (para desarrollo local)
- **PowerShell** (en Windows)

### Opci√≥n 1: Despliegue Completo con Docker (Recomendado)

```bash
# Clonar el repositorio
git clone https://github.com/RetoFit/RETOFIT_2.0.git
cd RETOFIT_2.0

# Levantar todos los servicios
docker-compose up --build

# Acceder a la aplicaci√≥n
# Landing page: https://localhost/
# Frontend: https://localhost/dashboard
# API: https://localhost/api/
```

### Opci√≥n 2: Desarrollo Local de Microfrontends

```powershell
# Usar el script de gesti√≥n (Windows)
.\microfrontends.ps1 install    # Instalar dependencias
.\microfrontends.ps1 dev        # Modo desarrollo

# O manualmente
cd landing-page
npm install
npm run dev  # Puerto 3001

# En otra terminal
cd front
npm install
npm run dev  # Puerto 3000
```

### Comandos √ötiles del Script de Microfrontends

```powershell
.\microfrontends.ps1 dev         # Iniciar ambos frontends en dev
.\microfrontends.ps1 build       # Construir para producci√≥n
.\microfrontends.ps1 docker-up   # Levantar con Docker
.\microfrontends.ps1 docker-down # Detener Docker
.\microfrontends.ps1 install     # Instalar dependencias
.\microfrontends.ps1 clean       # Limpiar node_modules
.\microfrontends.ps1 help        # Ver ayuda
```

### Acceso a la Aplicaci√≥n

Una vez desplegado el sistema:

| Componente | URL | Descripci√≥n |
|------------|-----|-------------|
| **Landing Page** | https://localhost/ | P√°gina de bienvenida |
| **Login** | https://localhost/login | Autenticaci√≥n |
| **Dashboard** | https://localhost/dashboard | Panel principal |
| **Admin** | https://localhost/admin | Administraci√≥n |
| **API Gateway** | https://localhost/api/ | Endpoints de API |
| **Circuit Breakers** | http://localhost:8081/actuator/ | Monitoreo |

### Variables de Entorno

**Landing Page** (`.env.local`):
```env
NEXT_PUBLIC_FRONTEND_URL=https://localhost
```

**Frontend Principal**: Configurado en `docker-compose.yaml`
```

